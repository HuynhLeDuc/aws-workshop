[
{
	"uri": "http://localhost:1313/aws-workshop/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Lê Đức Huỳnh\nSố điện thoại: 0365436310\nEmail: Huynhld.ai@gmail.com\nTrường: Đại học FPT\nNgành: Trí Tuệ Nhân Tạo\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 12/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Hiện đại hóa ứng dụng Java với Amazon Q Developer và Visual Studio Code Tác giả: Vimal Vyas và Shweta Singh – 01/04/2025\rAmazon Q, Amazon Q Developer, AWS Java Development, DevOps, Technical How-to | Permalink\rTheo thời gian, các tổ chức tiếp tục sử dụng các ứng dụng Java được xây dựng từ nhiều năm trước bằng các phiên bản Java Development Kit (JDK) cũ hơn. Điều này dẫn đến việc các ứng dụng chạy mã lỗi thời với các phụ thuộc lỗi thời. Sự kết hợp của các yếu tố này có thể dẫn đến lỗ hổng bảo mật, hiệu suất ứng dụng kém và các thách thức về bảo trì. Những thách thức này ngày càng khó quản lý trong các tổ chức chạy số lượng lớn ứng dụng Java. Các nhà phát triển đang tìm kiếm một môi trường phát triển hỗ trợ chạy các ứng dụng Java cũ với các JDK khác nhau; và các công cụ giúp tự động di chuyển ứng dụng sang phiên bản Java hiện tại, thay thế mã lỗi thời và sửa các phụ thuộc bị thiếu.\nVào tháng 4 năm 2024, Amazon Web Services (AWS) đã công bố Amazon Q Developer: Transform for Java chính thức ra mắt . Vào ngày 14 tháng 2 năm 2025, Amazon Q Developer đã công bố hỗ trợ nâng cấp lên Java 21. Với bản phát hành này, Amazon Q Developer: Transform bổ sung tính năng chuyển đổi chỉ bằng một cú nhấp chuột các ứng dụng Java 8 và Java 11 cũ sang Java 21.\nTổng quan về giải pháp Giải pháp bao gồm các bước sau để thiết lập môi trường phát triển của bạn: 1.Cấu hình Visual Studio Code với nhiều JDK và Maven 2.Tích hợp Visual Studio Code với Amazon Q Developer: Transform Sau khi môi trường phát triển được thiết lập, bạn có thể sử dụng tính năng Amazon Q Developer: Transform để chuyển đổi ứng dụng Java 8 hoặc Java 11 sang Java 21.\nThiết lập môi trường phát triển Cấu hình Visual Studio Code với nhiều JDKs Trong VSCode, chọn View/Command Palette, sau đó chọn Java: Configure Java runtime và tải về các phiên bản JDK 8, 11, và 21. Tùy chọn: sử dụng Amazon Corretto để tải nhiều phiên bản JDK. Amazon Corretto là một bản phân phối OpenJDK miễn phí, đa nền tảng và sẵn sàng cho môi trường production.\nĐể cài đặt plugin Maven, mở VSCode Extensions, tìm hoặc chọn Maven for Java và bấm Install. Bây giờ, hãy thêm các ứng dụng Java được xây dựng trên Java 8 và Java 11 vào không gian làm việc VSCode. Chúng tôi đang sử dụng các ứng dụng demo Java mẫu được phát triển với các phiên bản Java 8 và Java 11 cho hướng dẫn này. Hãy đảm bảo rằng tệp pom.xml trỏ đến phiên bản Java tương ứng như trong hình ảnh sau.\nTích hợp Visual Studio Code với Amazon Q Developer: Transform Amazon Q Developer cung cấp khả năng tích hợp với nhiều môi trường phát triển tích hợp (IDE) và VSCode là một trong số đó. Hãy làm theo tài liệu hướng dẫn của AWS để tích hợp VSCode với Amazon Q Developer .\nChuyển đổi ứng dụng Java Chuyển đổi Java 8 sang Java 21 Các bước sau đây sẽ hướng dẫn bạn thực hiện chuyển đổi mã:\nChọn Amazon Q trên thanh điều hướng ở bảng điều khiển phía dưới của VSCode. Sau đó, chọn \u0026ldquo;Open Chat panel\u0026rdquo; từ bảng lệnh. Trong bảng điều khiển trò chuyện, nhập /transform rồi chọn dự án Java 8 cần chuyển đổi. Bây giờ chọn phiên bản mã nguồn là 8 và phiên bản mã đích là 21. Chọn Xác nhận. Một cửa sổ bật lên sẽ mở ra với tiêu đề \u0026quot; Choose to skip unit tests\u0026quot; , chọn \u0026ldquo;Skip unit tests\u0026rdquo; và chọn \u0026ldquo;Confirm\u0026rdquo; . Chúng tôi sẽ bỏ qua unit test vì có một giới hạn kỹ thuật yêu cầu dự án phải có khả năng xây dựng và hoàn thành các bài kiểm tra trong vòng 55 phút. Một cửa sổ bật lên mới sẽ mở ra và cung cấp các tùy chọn để chọn cách nhận các thay đổi được đề xuất. Cửa sổ này cung cấp các tùy chọn Một Khác Biệt (One Diff) và Nhiều Khác Biệt (Multiple Diff). Chọn Một Khác Biệt (One Diff) cho các chuyển đổi quy mô nhỏ hơn với các thay đổi mã có thể quản lý được. Một cửa sổ bật lên cuối cùng sẽ mở ra để cung cấp lệnh tìm đường dẫn JDK. Chạy lệnh trong một terminal mới và sau đó nhập đường dẫn đến JDK 8. Sau khi nhập đường dẫn JDK, Amazon Q sẽ bắt đầu xây dựng dự án của bạn. Quá trình này có thể mất đến 10 phút tùy thuộc vào quy mô dự án của bạn. Xem lại kế hoạch Transformation Sau khi Amazon Q Developer tải lên và biên dịch mã của bạn trong môi trường biên dịch an toàn, nó sẽ tạo ra một kế hoạch chuyển đổi. Kế hoạch chuyển đổi này hiển thị chi tiết mã Java, bao gồm các dòng mã, các phụ thuộc cần thay thế, các phiên bản mã Java 8 đã lỗi thời và số lượng tệp cần thay đổi.\nXem lại Transformation Summary Sau khi hoàn tất quá trình chuyển đổi, Amazon Q Developer sẽ tạo một bản tóm tắt chuyển đổi chi tiết, liệt kê các phụ thuộc, các phiên bản mã Java 8 đã lỗi thời và danh sách tất cả các tệp đã thay đổi. Các phiên bản mã lỗi thời sau đây đã được Amazon Q Developer thay thế.\nAmazon Q Developer tóm tắt các thay đổi được đề xuất trong tab \u0026ldquo;Thay đổi được đề xuất\u0026rdquo;, mở ra sau khi quá trình chuyển đổi hoàn tất. Để chấp nhận các thay đổi do Amazon Q thực hiện, hãy vào tab \u0026ldquo;Thay đổi được đề xuất\u0026rdquo; và chọn \u0026ldquo;Chấp nhận\u0026rdquo; Chuyển đổi Java 11 sang Java 21 Quy trình tương tự như trên, chỉ khác ở bước chọn Java 11 làm source version. Bao gồm: · Lựa chọn dự án và thông số kỹ thuật phiên bản · Xây dựng thiết lập môi trường · Xem xét kế hoạch chuyển đổi · Chấp nhận những thay đổi cuối cùng\nKiểm thử đơn vị Các doanh nghiệp cũng phải đối mặt với những thách thức như tỷ lệ lỗi cao, vấn đề chất lượng và chu kỳ phát triển dài cho các tính năng và ứng dụng mới. Amazon Q Developer giúp các nhóm phát triển cải thiện năng suất bằng cách tự động hóa các tác vụ thông thường và giảm thiểu nợ kỹ thuật tích lũy thông qua tính năng /test.\nTính năng /test trong Amazon Q Developer là một chức năng tạo bài kiểm tra đơn vị tự động, giúp các nhà phát triển tạo ra các bộ kiểm tra toàn diện. Sau đây là một ví dụ về cách tạo một bài kiểm tra đơn vị:\nĐể chạy thử nghiệm, hãy điều hướng đến tab Kiểm tra và chọn lớp kiểm tra Java đã tạo. Từ tab kiểm tra này, bạn có toàn quyền kiểm soát để chạy bất kỳ thử nghiệm nào, dù là một trường hợp kiểm tra đơn lẻ hay nhiều trường hợp kiểm tra.\nLợi ích và tác động Amazon Q Developer đóng vai trò là trợ lý AI mạnh mẽ giúp chuyển đổi và hiện đại hóa quá trình phát triển phần mềm trong toàn bộ vòng đời, mang lại những lợi ích sau – · Đẩy nhanh quá trình hiện đại hóa mã · Đơn giản hóa việc quản lý sự phụ thuộc · Giảm nợ kỹ thuật · Nâng cao hiệu suất ứng dụng · Đơn giản hóa việc bảo trì\nPhần kết luận Amazon Q Developer Agent for Code Transformation (QCT) for Java giúp hiện đại hóa các ứng dụng Java cũ nhanh hơn và hiệu quả hơn. Công cụ này chuyển đổi các hệ thống lỗi thời sang các framework hiện tại và triển khai chúng dưới dạng ứng dụng đám mây gốc trên AWS. Quy trình này giảm thiểu công sức, rủi ro và nhu cầu bảo trì liên tục. Bằng cách sử dụng Amazon Q Developer, bạn sẽ tiết kiệm thời gian và nguồn lực trước đây dành cho việc quản lý nợ kỹ thuật, cho phép nhóm của bạn tập trung vào đổi mới và cải tiến các ứng dụng mới được hiện đại hóa.\nNhư đã trình bày trong bài viết này, các nhà phát triển có thể chuyển đổi nhiều ứng dụng Java được xây dựng trên các phiên bản JDK khác nhau bằng Amazon Q Developer và VSCode. Các nhà phát triển cũng có thể tận dụng tính năng /test của Amazon Q Developer để nhanh chóng tạo các trường hợp kiểm thử đơn vị. Công cụ này giúp giảm thiểu độ phức tạp và thời gian cần thiết để hiện đại hóa các ứng dụng Java cũ, cho phép các nhà phát triển tập trung vào đổi mới thay vì bảo trì.\n"
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Modernizing trading workloads with next-generation AWS Outposts racks Tác giả: Jim Cotis – 01/05/2025\r"
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Chỉnh sửa Amazon EBS volumes trên Kubernetes với Volume Attribute Class by pmm on 05 MAR 2025 in | Containers, Technical How-to, Permalink, Bài viết này được đồng tác giả bởi Kevin Liu (Senior PMT), Jens-Uwe Walther (Senior STAM-Containers), và Drew Sirenko (Software Dev Engineer).\nGiới thiệu Trong bài viết này, chúng ta khám phá cách sửa đổi Amazon Elastic Block Store (Amazon EBS) volumes trên Kubernetes mà không cần dừng ứng dụng. Tìm hiểu cách sử dụng VolumeAttributesClass API cùng với Amazon EBS Container Storage Interface (CSI) driver để điều chỉnh hiệu năng provisioned performance, di chuyển sang gp3 volumes, và tự động hóa quy trình sao lưu dữ liệu của bạn.\nCác ứng dụng container hóa hiện đại sử dụng bộ nhớ persistent, như phân tích dữ liệu, cơ sở dữ liệu, hoặc mã hóa/giải mã video, cần nhiều đặc tính lưu trữ khác nhau như độ trễ thấp, thông lượng cao, hoặc nhiều hơn nữa. Amazon EBS rất phù hợp cho các workload này. EBS volumes cung cấp nhiều loại lưu trữ khác nhau, các thuộc tính lưu trữ có thể cấu hình như IOPS và throughput, và khả năng thay đổi các thuộc tính này mà không làm gián đoạn.\nNếu bạn triển khai các workload stateful trên Kubernetes, bạn có thể sử dụng Amazon EBS CSI driver để provision và quản lý EBS volumes thay bạn. Khi bạn tạo Persistent Volume Claim (PVC) với kích thước cụ thể và Storage Class (SC), Kubernetes sẽ phối hợp với Amazon EBS CSI driver để triển khai workload với lưu trữ cần thiết bằng cách tạo, attach và format EBS volume.\nViệc thay đổi đặc tính lưu trữ của volumes trong Kubernetes trước đây là thao tác offline, yêu cầu operator phải tạo SC mới, và migrate sang PVC và Persistent Volume (PV) mới. Quy trình này cần downtime và ảnh hưởng đến availability. Vì lý do đó, năm 2023, AWS phát hành volume-modifier-for-k8s sidecar, cho phép cập nhật online các đặc điểm volume bằng cách áp dụng annotations lên PVC. Mặc dù đây là giải pháp quan trọng, AWS đã hợp tác với các nhà cung cấp lưu trữ khác để tạo một giải pháp sửa đổi volume được cung cấp dưới dạng native Kubernetes API. Trong năm qua, AWS đã làm việc với cộng đồng Kubernetes để phát hành VolumeAttributesClass Kubernetes Enhancement, đã đạt beta trong Kubernetes 1.31. Dù tính năng bị disable mặc định trong upstream Kubernetes, nó được enable tự động cho bạn trong Amazon Elastic Kubernetes Service (Amazon EKS) 1.31.\nBắt đầu từ Amazon EKS 1.31, bạn có thể sử dụng VolumeAttributesClass (VAC) để sửa đổi volume type, IOPS hoặc throughput của EBS volumes mà không cần volume-modifier-for-k8s sidecar. Hơn nữa, bạn có thể dùng VAC để thêm, chỉnh sửa và xóa AWS resource tags từ volumes của bạn. Amazon EBS CSI driver enable tính năng này mặc định khi bạn nâng cấp lên phiên bản 1.35.0 hoặc mới hơn.\nSử dụng Amazon EKS 1.31 và Amazon EBS CSI driver 1.35.0, bạn đã có thể bắt đầu dùng VAC thay cho PVC annotations. Trong hai phần tiếp theo, chúng tôi giới thiệu VolumeAttributesClasses và cách bật tính năng này trên cluster. Sau đó, chúng tôi hướng dẫn ba workflow phổ biến để sửa đổi volumes với VAC:\nĐiều chỉnh throughput và IOPS của volumes. Di chuyển sang EBS gp3 volumes để tiết kiệm đến 20% chi phí mỗi GB so với gp2. Sửa đổi resource tags của EBS volume để tự động hóa workflow backup bằng Amazon Data Lifecycle Manager. Tổng quan về giải pháp Cluster operators có thể dựa vào Amazon EBS CSI driver để quản lý declarative persistent volumes. Bạn có thể yêu cầu persistent storage cho workload bằng PVC với size, SC và VAC cụ thể.\nMột VAC bao gồm tên, driverName của CSI driver, và danh sách mutable parameters cụ thể đối với storage provider như Amazon EBS.\nCác tham số mutable EBS volume như throughput, IOPS, volume types và resource tags có thể được chỉ định trong VAC:\n*apiVersion: storage.k8s.io/v1beta1 kind: VolumeAttributesClass metadata: name: ebs-blog-gp3-standard-performance driverName: ebs.csi.aws.com parameters: type: gp3 iops: \u0026#34;3000\u0026#34; throughput: \u0026#34;125\u0026#34; tagSpecification_1: \u0026#34;performance=standard\u0026#34;* Bạn có thể thêm VAC vào PVC bằng trường spec.volumeAttributesClassName:\n*apiVersion: v1 kind: PersistentVolumeClaim metadata: name: ebs-blog-overview spec: ... volumeAttributesClassName: ebs-blog-gp3-standard-performance* Volume được provision với các parameters trong VAC và SC, với VAC ưu tiên hơn khi có xung đột. VAC của PVC cũng override mọi thay đổi dựa trên annotations, và ngăn các thay đổi annotation trong tương lai.\nViệc tách riêng VAC mang lại lợi ích khi các tổ chức tách biệt vai trò vận hành cluster và triển khai ứng dụng. Operator có thể tạo SC và VAC ở phạm vi cluster, sau đó application developers có thể sử dụng chúng trong PVC thuộc namespace của họ.\nĐiều kiện tiên quyết Trên Amazon EKS 1.31 trở lên, VolumeAttributesClass feature gate và API storage.k8s.io/v1beta1 được enable tự động trên control plane. Ngoài ra, bạn phải sử dụng Amazon EBS CSI driver v1.35.0 hoặc mới hơn, được cài đặt qua Amazon EKS Managed add-on v1.35.0-eksbuild.2 hoặc Helm chart v2.35.1.\nNếu bạn vận hành self-managed Kubernetes v1.31 (như kOps), bạn phải enable VolumeAttributesClass feature gate trên kube-apiserver, kube-scheduler và kube-controller-manager, và enable storage.k8s.io/v1beta1 API qua runtime-config của kube-apiserver.\nTham khảo tài liệu Kubernetes VolumeAttributesClass để xem đầy đủ yêu cầu.\nĐể sửa đổi Amazon EBS resource tags qua VAC, đảm bảo bạn đính kèm IAM Policy sau vào role của Amazon EBS CSI driver:\n*{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:CreateTags\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:ec2:*:*:volume/*\u0026#34;, \u0026#34;arn:aws:ec2:*:*:snapshot/*\u0026#34; ] } ] }* Hướng dẫn Các bước sau sẽ hướng dẫn qua giải pháp này.\nCung cấp một khối lượng và tăng hiệu suất của nó Amazon EKS 1.31 không có SC mặc định. Chúng ta phải tạo SC sau:\n$ kubectl apply -f - \u0026lt;\u0026lt;EOF apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: ebs-blog-sc provisioner: ebs.csi.aws.com allowVolumeExpansion: true EOF Dưới đây là hai VAC ví dụ, mỗi cái có QoS khác nhau:\n$ kubectl apply -f - \u0026lt;\u0026lt;EOF apiVersion: storage.k8s.io/v1beta1 kind: VolumeAttributesClass metadata: name: ebs-blog-gp3-standard-performance driverName: ebs.csi.aws.com parameters: type: gp3 iops: \u0026#34;3000\u0026#34; throughput: \u0026#34;125\u0026#34; --- apiVersion: storage.k8s.io/v1beta1 kind: VolumeAttributesClass metadata: name: ebs-blog-gp3-increased-performance driverName: ebs.csi.aws.com parameters: type: gp3 iops: \u0026#34;4000\u0026#34; throughput: \u0026#34;130\u0026#34; EOF Provision volume với VAC standard:\n$ kubectl apply -f - \u0026lt;\u0026lt;EOF apiVersion: v1 kind: PersistentVolumeClaim metadata: name: ebs-blog-claim spec: accessModes: - ReadWriteOnce storageClassName: ebs-blog-sc volumeAttributesClassName: ebs-blog-gp3-standard-performance resources: requests: storage: 10Gi EOF Để tăng hiệu năng, bạn patch PVC sang VAC mới:\n$ kubectl patch pvc ebs-blog-claim -p \u0026#39;{\u0026#34;spec\u0026#34;: { \u0026#34;volumeAttributesClassName\u0026#34;: \u0026#34;ebs-blog-gp3-increased-performance\u0026#34; }}\u0026#39; EBS CSI driver sẽ thấy VAC hiện tại và VAC mong muốn khác nhau, sửa đổi volume và update PV.\nBạn chỉ có thể sửa một volume mỗi 6 giờ theo tài liệu EBS. Vì vậy bạn nên gộp tăng size PVC và VAC update vào một patch:\n$ kubectl patch pvc ebs-blog-claim --type json -p \u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/volumeAttributesClassName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;ebs-blog-gp3-increased-performance\u0026#34; }, {\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/resources/requests/storage\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;11Gi\u0026#34;}]\u0026#39; Nếu không bạn sẽ thấy lỗi sau trên PVC:\nVolumeResizeFailed: ... VolumeModificationRateExceeded: You\u0026#39;ve reached the maximum modification rate per volume limit. Wait at least 6 hours between modifications per EBS volume. Tiết kiệm chi phí bằng cách di chuyển sang ổ đĩa gp3 VAC có thể dùng với PVC đã tạo từ trước không có VAC, rất hữu ích để migrate từ gp2 sang gp3. EBS gp3 cho phép provision IOPS và throughput độc lập với storage size. Bạn có thể migrate gp2 → gp3 trong mọi use case trước đây, và có thể tiết kiệm đến 20% chi phí.\nDưới đây là ví dụ workload stateful dùng gp2 volume:\n$ kubectl apply -f - \u0026lt;\u0026lt;EOF apiVersion: v1 kind: PersistentVolumeClaim metadata: name: ebs-blog-migration spec: accessModes: - ReadWriteOnce storageClassName: ebs-blog-migration resources: requests: storage: 1Gi --- apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: ebs-blog-migration provisioner: ebs.csi.aws.com allowVolumeExpansion: true volumeBindingMode: WaitForFirstConsumer parameters: type: gp2 --- apiVersion: v1 kind: Pod metadata: name: ebs-blog-migration-app spec: containers: - name: ebs-blog-app image: centos command: [\u0026#34;/bin/sh\u0026#34;] args: [\u0026#34;-c\u0026#34;, \u0026#34;while true; do echo $(date -u) \u0026gt;\u0026gt; /data/out.txt; sleep 5; done\u0026#34;] volumeMounts: - name: persistent-storage mountPath: /data volumes: - name: persistent-storage persistentVolumeClaim: claimName: ebs-blog-migration EOF Để migrate volume sang gp3, trước tiên apply VAC:\n$ kubectl apply -f - \u0026lt;\u0026lt;EOF apiVersion: storage.k8s.io/v1beta1 kind: VolumeAttributesClass metadata: name: ebs-blog-gp3 driverName: ebs.csi.aws.com parameters: type: gp3 EOF Sau đó patch PVC:\n$ kubectl patch pvc ebs-blog-migration -p \u0026#39;{\u0026#34;spec\u0026#34;: {\u0026#34;volumeAttributesClassName\u0026#34;: \u0026#34;ebs-blog-gp3\u0026#34;}}\u0026#39; Lưu ý: tính đến Kubernetes 1.31, bạn không thể sửa đổi volumes tham chiếu SC kiểu in-tree. Hãy đảm bảo SC dùng provisioner ebs.csi.aws.com, không phải kubernetes.io/aws-ebs.\nWorkflow modify tags Để quản lý dễ dàng hơn EBS volumes, bạn có thể dùng tags. Tags là các cặp key-value gán cho AWS resources, cho phép phân loại tài nguyên theo mục đích, owner hoặc environment. Với nhiều volumes, tags giúp xác định hoặc nhóm tài nguyên.\nEBS CSI driver cho phép thêm, thay thế, xóa volume tags qua parameter tagSpecification trong VAC.\nNgoài ra, tags có thể dùng với Amazon Data Lifecycle Manager để tự động backup volumes. EBS Snapshots ghi lại trạng thái volume tại thời điểm cụ thể để khôi phục khi mất dữ liệu. Bạn có thể tạo chính sách DLM backup dựa vào tags.\nVí dụ chính sách sau tạo snapshot mỗi ngày cho các volume dùng VAC ebs-blog-daily-backup:\n$ aws dlm get-lifecycle-policies { \u0026#34;Policies\u0026#34;: [ { \u0026#34;PolicyId\u0026#34;: \u0026#34;policy-045203fd0b8e2bf79\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;This policy creates daily backups of my K8s PVs\u0026#34;, \u0026#34;State\u0026#34;: \u0026#34;ENABLED\u0026#34;, \u0026#34;Tags\u0026#34;: { \u0026#34;backup-interval\u0026#34;: \u0026#34;daily\u0026#34; }, \u0026#34;PolicyType\u0026#34;: \u0026#34;EBS_SNAPSHOT_MANAGEMENT\u0026#34;, \u0026#34;DefaultPolicy\u0026#34;: false } ] } Dọn dẹp Để tránh phát sinh chi phí, xóa các resources đã tạo:\nkubectl delete pod ebs-blog-migration-app kubectl delete pvc ebs-blog-claim kubectl delete pvc ebs-blog-migration kubectl delete vac ebs-blog-gp3 kubectl delete vac ebs-blog-gp3-increased-performance kubectl delete vac ebs-blog-gp3-standard-performance kubectl delete vac ebs-blog-daily-backup kubectl delete sc ebs-blog-sc kubectl delete sc ebs-blog-migration Bạn có thể kiểm tra việc xóa volumes trong EC2 console.\nPhần kết luận Trong bài viết này, chúng tôi khám phá cách sửa đổi Amazon EBS volumes trên Kubernetes với VolumeAttributesClasses. Tính năng mới này giúp bạn tinh chỉnh hiệu năng volume bằng cách cập nhật volume type, IOPS và throughput mà không cần downtime. Hơn nữa, bạn có thể tự động hóa backup bằng cách chỉnh sửa resource tags phù hợp với Amazon Data Lifecycle Manager.\n"
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Bài Thu Hoạch Sự Kiện “Cloud Day” Mục Đích Của Sự Kiện Sự kiện “Cloud Day” được tổ chức nhằm giới thiệu xu hướng phát triển AI tại Việt Nam, đặc biệt là bước tiến từ Generative AI sang Agentic AI. Các diễn giả cũng trình bày các giải pháp mới của AWS như Amazon Bedrock, AgentCore, và SageMaker Unified Studio – những công cụ hỗ trợ doanh nghiệp xây dựng, triển khai và vận hành AI agent một cách nhanh chóng và an toàn.\nDiễn Giả Kien Nguyen – Solutions Architect Jun Kai Loke – AI/ML Specialist SA, AWS Tamelly Lim – Storage Specialist SA, AWS Binh Tran – Senior Solutions Architect, AWS Taiki Dang – Solutions Architect, AWS Michael Armentano – Principal WW GTM Specialist, AWS Nội Dung Chính Tác động của AI đối với kinh tế Việt Nam AI dự kiến đóng góp 120–130 tỷ USD (khoảng 25% GDP) vào năm 2040. Quy mô thị trường AI hiện đạt 750 triệu USD, tăng trưởng 15–18% mỗi năm. Việt Nam có khoảng 765 startup AI, xếp thứ 2 trong ASEAN. Dù tiềm năng lớn, Việt Nam vẫn đang trong giai đoạn đầu, cần đầu tư thêm về hạ tầng, nhân lực và chính sách hỗ trợ. Hành trình phát triển: từ Generative AI → Agentic AI Công nghệ AI đang chuyển từ công cụ hỗ trợ tạo nội dung sang hệ thống có khả năng hành động độc lập. Agentic AI cho phép nhiều agent phối hợp để hoàn thành các nhiệm vụ phức tạp. Mức độ tự động hóa ngày càng cao, giảm dần sự can thiệp trực tiếp của con người. Ứng dụng Agentic AI trong doanh nghiệp Tăng năng suất, giảm tải công việc lặp lại, hỗ trợ đổi mới sáng tạo. Đến 2028, dự báo 33% ứng dụng doanh nghiệp sẽ tích hợp Agentic AI. Khoảng 15% các quyết định vận hành thường ngày có thể được tự động hóa. Amazon Bedrock – Nền tảng AI tổng hợp Cung cấp nhiều mô hình từ các nhà cung cấp hàng đầu. Hỗ trợ tùy chỉnh mô hình bằng dữ liệu riêng, đảm bảo bảo mật và tối ưu chi phí. Có sẵn cơ chế Responsible AI. Cung cấp nền tảng triển khai AI agent nhanh chóng, dễ mở rộng, dễ tích hợp. Amazon Bedrock AgentCore Khung triển khai agent bảo mật, có khả năng mở rộng. Tương thích với các framework phổ biến: LangChain, CrewAI, LangGraph, Strands Agents. Hỗ trợ quản lý memory ngắn hạn, dài hạn và semantic search. Cho phép tích hợp, theo dõi và khám phá công cụ linh hoạt. Hạ tầng dữ liệu và AI hiện đại SageMaker Unified Studio đóng vai trò trung tâm cho dữ liệu, phân tích, và AI.\nTích hợp chặt chẽ với:\nRedshift, Athena, EMR, Glue – xử lý và quản lý dữ liệu. QuickSight – trực quan hóa. Bedrock – xây dựng ứng dụng GenAI. Hỗ trợ mô hình Zero-ETL giữa S3 và Redshift, giúp đơn giản hóa luồng dữ liệu.\nMô hình Data Lakehouse Hỗ trợ đa dạng các hệ thống lưu trữ: S3 Tables, Redshift Managed Storage. Kết nối dữ liệu từ nhiều nguồn lớn như Aurora, DynamoDB, MSK, Kinesis, Salesforce, SAP, Facebook Ads, v.v. Những Gì Tôi Học Được Về tư duy AI và Cloud Hiểu rõ sự khác biệt giữa Generative AI và Agentic AI – hướng phát triển tất yếu của ngành. Nhận thức rằng Agentic AI không chỉ trả lời mà còn hành động và ra quyết định. Nắm được khả năng của Bedrock trong xây dựng hệ thống AI thông minh và tự động hóa. Về kiến trúc kỹ thuật Hình dung được cách Bedrock kết hợp với SageMaker, Redshift và S3 trong một hệ sinh thái AI hoàn chỉnh. Hiểu cách AWS xử lý các phần phức tạp như memory, tool discovery và quan sát agent (observability). Ứng Dụng Thực Tế Ứng dụng Amazon Titan Embeddings để tạo embedding cho dự án hiện tại. Thử nghiệm mô hình Zero-ETL giữa Aurora/DynamoDB và Redshift. Tìm hiểu khả năng xây dựng tác tử AI tự động hóa quy trình doanh nghiệp bằng AgentCore thay vì dùng Lambda thủ công. Trải Nghiệm Tại Sự Kiện Tham gia Cloud Day giúp tôi có góc nhìn rõ ràng hơn về cách AI, đặc biệt Agentic AI, đang thay đổi cách doanh nghiệp vận hành.\nGiao lưu với các chuyên gia AWS Các diễn giả chia sẻ nhiều ví dụ thực tế về cách Amazon ứng dụng AI trong quy mô lớn. Hiểu sâu hơn cách hệ thống multi-agent vận hành trong môi trường doanh nghiệp. Trải nghiệm kỹ thuật Tìm hiểu hoạt động của AgentCore từ quản lý memory đến tích hợp công cụ. Nắm được cách dữ liệu được luân chuyển giữa S3 – Redshift – SageMaker trong các ứng dụng AI. Thấu hiểu mô hình Lakehouse và Zero-ETL. Bài học rút ra Agentic AI là bước tiến không thể tránh khỏi nếu doanh nghiệp muốn tự động hóa ở quy mô lớn. Hạ tầng AI hiện đại phải dựa trên cloud và dữ liệu. AWS đang dẫn đầu trong việc cung cấp nền tảng đầy đủ cho AI/ML. Hình Ảnh Tại Sự Kiện Tổng thể, sự kiện không chỉ mang đến cho tôi kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tiếp cận trong việc thiết kế ứng dụng, hiện đại hóa hệ thống và nâng cao khả năng phối hợp giữa các nhóm. Đây thực sự là một trải nghiệm giá trị, giúp tôi nhìn nhận rõ hơn cách xây dựng các giải pháp hiệu quả và linh hoạt trong môi trường doanh nghiệp.\n"
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Báo cáo thu hoạch “Generative AI cùng Amazon Bedrock” Mục tiêu của buổi hội thảo Trang bị kiến thức cơ bản về Generative AI và điểm khác biệt so với Machine Learning cổ điển. Mô tả chi tiết dịch vụ Amazon Bedrock và các mô hình nền (Foundation Models). Hướng dẫn kỹ thuật RAG (Retrieval Augmented Generation) để phát triển ứng dụng AI thông minh, chính xác và giảm thiểu lỗi ảo giác. Giới thiệu hệ thống các dịch vụ AI chuyên sâu của AWS. Danh sách người trình bày Lâm Tuấn Kiệt - Kỹ sư DevOps cấp cao, FPT Software. Danh Hoàng Hiếu Nghĩa - Kỹ sư AI, Renova Cloud. Đinh Lê Hoàng Anh - Thực tập sinh Kỹ sư Đám mây, First Cloud AI Journey. Nội dung chính Xu hướng chuyển đổi: Mô hình ML truyền thống và Mô hình nền Mô hình ML truyền thống: Tập trung vào những nhiệm vụ riêng lẻ (Specific tasks), yêu cầu dữ liệu được dán nhãn (Labeled data), quy trình Huấn luyện/Triển khai phức tạp cho từng mục tiêu. Mô hình nền (FM): Được đào tạo trên khối lượng dữ liệu không cấu trúc khổng lồ (Unlabeled data), có thể thích ứng cho nhiều tác vụ khác nhau như: Tạo văn bản, Tóm tắt, Hỏi đáp, Chatbot. Hệ sinh thái AI trên nền tảng AWS Amazon Bedrock: Nền tảng tập hợp các mô hình FM hàng đầu từ các đối tác của AWS (AI21 Labs, Anthropic, Cohere, Meta, Stability AI,\u0026hellip;) và mô hình của chính Amazon. Các Dịch vụ AI Chuyên biệt của AWS: Có thể xem như những \u0026ldquo;giải pháp có sẵn\u0026rdquo;, được tối ưu cho từng tác vụ cụ thể mà không cần huấn luyện mô hình: Amazon Rekognition: Nhận diện đối tượng, Nhận diện khuôn mặt, Nhận diện cảm xúc, Nhận diện người nổi tiếng, Phân tích video - 0.001$/ảnh cho 1 triệu ảnh đầu. Amazon Translate: Dịch văn bản đa ngôn ngữ thời gian thực với độ chính xác cao và văn phong tự nhiên. Amazon Textract: Trích xuất thông tin có cấu trúc (bảng biểu, mẫu đơn) từ tài liệu scan hoặc PDF. Amazon Transcribe: Chuyển đổi giọng nói thành văn bản. Amazon Polly: Chuyển đổi văn bản thành giọng nói. Amazon Comprehend: Phân tích cảm xúc văn bản, trích xuất từ khóa và phân loại chủ đề tự động. Amazon Kendra: Cho phép tìm kiếm thông tin trong tài liệu nội bộ bằng ngôn ngữ tự nhiên. Amazon Lookout: Phát hiện bất thường trong dây chuyền sản xuất hoặc thiết bị công nghiệp để bảo trì dự đoán. Amazon Personalize: Xây dựng hệ thống đề xuất theo thời gian thực dựa trên công nghệ học máy. Kỹ thuật Định hướng (Prompting): Chuỗi suy nghĩ (Chain of Thought - CoT) So sánh giữa Định hướng Tiêu chuẩn (hỏi trực tiếp kết quả) và Định hướng Chuỗi Suy nghĩ. CoT hướng dẫn mô hình lập luận từng bước để giải quyết các bài toán logic phức tạp, giúp cải thiện đáng kể độ chính xác so với việc chỉ đưa ra câu trả lời cuối. Kỹ thuật RAG (Retrieval Augmented Generation) – Trọng tâm kỹ thuật Vấn đề: Giải quyết hiện tượng \u0026ldquo;ảo giác\u0026rdquo; và thiếu thông tin cập nhật của các mô hình LLM. Giải pháp: Kết hợp khả năng truy xuất (Retrieval) từ Cơ sở Kiến thức bên ngoài với khả năng tạo sinh (Generation) của LLM. Quy trình thu thập dữ liệu (Data Ingestion): Dữ liệu thô (New data) → Chia nhỏ (Chunking). Xử lý qua Mô hình Embedding (ví dụ: Amazon Titan Text Embeddings V2.0). Lưu trữ dưới dạng vector vào Kho lưu trữ Vector (OpenSearch Serverless, Pinecone, Redis\u0026hellip;). RetrieveAndGenerate API: API quản lý toàn bộ quy trình từ nhận đầu vào người dùng → tạo query embedding → truy xuất dữ liệu → bổ sung ngữ cảnh (augment prompt) → tạo ra câu trả lời. Kiến thức thu nhận được Về Tư duy AI và Đám mây Hiểu rõ khi nào nên sử dụng Các Dịch vụ AI Chuyên biệt cho bài toán nhanh, cụ thể và khi nào dùng Bedrock/GenAI cho bài toán sáng tạo, phức tạp. Nắm vững tư duy thiết kế hệ thống RAG: Không chỉ đơn thuần là gọi API LLM, mà là bài toán quản lý dữ liệu và vector hóa để cung cấp ngữ cảnh chính xác cho AI tạo ra phản hồi tốt hơn. Về Kiến trúc Kỹ thuật Kỹ thuật Chuỗi Suy nghĩ (CoT) là chìa khóa để tối ưu kết quả đầu ra của mô hình mà không cần tinh chỉnh (fine-tuning). Hiểu sâu vai trò của Amazon Titan Embeddings V2.0 trong việc chuyển đổi văn bản đa ngôn ngữ thành vector (hỗ trợ 100+ ngôn ngữ, kích thước vector linh hoạt 256/512/1024). Kế hoạch áp dụng vào công việc Ứng dụng Amazon Bedrock cho dự án hiện tại: Amazon Rekognition để nhận diện món ăn từ ảnh nhằm tự động điền thông tin calo; Amazon Comprehend để phân tích văn bản nhằm chuẩn hóa tên món ăn và ghi nhận dữ liệu calo. Thử nghiệm áp dụng kỹ thuật RAG cho dự án hiện tại. Sử dụng Bedrock Agents để điều phối các tác vụ như truy vấn món ăn từ kho vector, tính toán mục tiêu calo và xây dựng thực đơn hàng ngày. Trải nghiệm tham gia sự kiện Tham gia workshop Generative AI với Amazon Bedrock đem lại góc nhìn thực tế về cách xây dựng ứng dụng AI hiện đại, từ lý thuyết nền tảng đến triển khai thực tế.\nKiến thức thực tiễn từ chuyên gia Các diễn giả đã trình bày rõ ràng luồng dữ liệu trong một hệ thống RAG, giúp tôi hình dung được cách hoạt động phía sau các ứng dụng Chatbot hiện nay. Việc phân tích rõ ràng sự khác biệt giữa Mô hình ML truyền thống và Generative AI giúp tôi định hình lại chiến lược lựa chọn công nghệ cho các dự án sắp tới. Trải nghiệm công nghệ Ấn tượng với RetrieveAndGenerate API của Bedrock vì nó giúp giảm đáng kể công sức lập trình thủ công cho phần kết nối giữa Kho Vector và LLM. Thấy được sức mạnh của Amazon Titan Embedding trong hỗ trợ đa ngôn ngữ, rất phù hợp với ứng dụng tại thị trường Việt Nam. Bài học rút ra RAG là tiêu chuẩn mới: Để ứng dụng AI trong doanh nghiệp, RAG gần như bắt buộc để đảm bảo tính chính xác và bảo mật dữ liệu. Hệ sinh thái toàn diện: AWS cung cấp đầy đủ từ hạ tầng (Kho Vector) đến tầng mô hình (Bedrock) và tầng ứng dụng (Agents), giúp việc triển khai trở nên nhanh chóng hơn nhiều. Một Số Hình Ảnh Khi Tham Gia Sự Kiện Tổng quan, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các nhóm.\n"
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về Amazon Bedrock Amazon Bedrock là dịch vụ machine learning được quản lý hoàn toàn của AWS, cung cấp khả năng truy cập đến các mô hình nền tảng (Foundation Models) hàng đầu từ Anthropic (Claude), Amazon (Titan), Meta (Llama), và nhiều nhà cung cấp khác thông qua API đơn giản.\nAnthropic Claude - Claude 2, Claude 3 Meta Llama - Llama 2 Amazon Titan - Titan Text AI21 Labs - Jurassic-2 Tổng quan về workshop Trong workshop này, bạn sẽ học cách:\nKhám phá Bedrock Console\nTạo AI Agent với AWS Lambda\nExpose API cho ứng dụng bên ngoài\nKiểm thử với giao diện web đơn giản\nNguồn hình ảnh\n"
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/5-workshop/5.3-vpc-to-internet/5.3.1-create-gwe/",
	"title": "Khám phá bedrock",
	"tags": [],
	"description": "",
	"content": " Search Amazon Bedrock pricing Mình xem xét giá cả từng loại model và miền xem có phù hợp với nhu cầu của mình hay không Mở AWS Console → Amazon Bedrock Chọn model catalog , chọn 1 model bất kỳ để test sao cho phù hợp với mục đích và giá tiền của bạn Mình ở đây sẽ chọn Amazon Nova 2 lite vì nó rẻ ($0.0003/per 1000 tokens) Chọn vào Open in Playground Thử prompt và cho kết quả Kết quả model đưa ra là khá ấn tượng . "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Tuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Tìm hiểu và cấu hình Amazon VPC\nTuần 3: Triển khai và Quản lý Amazon EC2 trên Windows và Linux\nTuần 4: Triển khai IAM Role và Làm việc với AWS Cloud9\nTuần 5: Triển khai và Quản lý Website Tĩnh với Amazon S3\nTuần 6: Làm việc với Amazon RDS – Tạo, Cấu hình, Kết nối \u0026amp; Vận hành Cơ sở dữ liệu trên AWS\nTuần 7: AWS CloudWatch \u0026amp; Hybrid DNS với Route 53 Resolver\nTuần 8: AWS DynamoDB \u0026amp; ElastiCache\nTuần 9: Tối ưu chi phí EC2 với AWS Lambda\nTuần 10: DMS - Giới thiệu và viết Lambda function\nTuần 11: Serverless - Sử dụng Amplify Authentication và Storage \u0026amp; Serverless - Hướng dẫn viết Front-end gọi API Gateway\nTuần 12: AI Agent with Amazon Bedrock on AWS\n"
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Tạo Knowledge Base",
	"tags": [],
	"description": "",
	"content": "Knowledge Base là gì ? Knowledge Base (Cơ sở kiến thức) là \u0026ldquo;bộ nhớ riêng\u0026rdquo; để Agent truy cập thông tin chuyên biệt của bạn, mà mô hình AI gốc không biết.\nỞ trang giao diện của Aws Bedrock mình chọn phía trái Knowledge Base Khi bạn cấu hình xong rồi , đợi khoảng 5 phút để nó khởi tạo . Như thế này đã tạo xong Knowledge base. Lưu ý bạn nên cấu hình theo nhu cầu và nên cấp quyền cần thiết cho nó\n"
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách tạo và quản lý chi phi với tài khoản AWS. Cách dùng console \u0026amp; CLI để tương tác và quản lý các dịch vụ. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 08/09/2025 08/09/2025 3 - Tìm hiểu AWS và các loại dịch vụ cơ bản + Compute (EC2) + Storage (S3) + Networking (VPC) + Database (RDS) 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Quản lý danh tính và quyền truy cập + Cài AWS CLI \u0026amp; cấu hình + Sử dụng AWS CLI với các thao tác cơ bản 10/09/2025 10/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu cách quản lý chi phí hiệu quả với AWS budget + Budget + Cost Budget, + Usage Budget + Reservation (RI) Budget + Saving plans Budget - Thực hành: + Tạo Cost Budget + Tạo Usage Budget + Tạo RI Budget + Tạo Savings Plans Budget + Dọn Dẹp Tài Nguyên 11/09/2025 11/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu về dịch vụ AWS Support - Các gói hỗ trợ của AWS + Gói Basic, Developer, Business và Enterprise - Các loại yêu cầu hỗ trợ + Hỗ trợ Tài khoản và Thanh toán + Hỗ trợ nâng hạn mức dịch vụ + Hỗ trợ Kỹ thuật - Thực hành: + Chọn gói hỗ trợ Basic + Tạo yêu cầu hỗ trợ 12/09/2025 12/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 1: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute: Cung cấp tài nguyên xử lý cho ứng dụng như máy ảo, container,\u0026hellip; Storage: Dùng để lưu trữ dữ liệu, sao lưu và phục hồi Networking: Quản lý hạ tầng mạng, bảo mật, và kết nối giữa các tài nguyên AWS. Database: Cung cấp dịch vụ quản lý cơ sở dữ liệu quan hệ và phi quan hệ. Đã tạo cấu hình và định danh AWS Free Tier account thành công.\nĐã biết tạo và quản lý Group user, User.\nBiết cách đăng nhập bằng IAM và các user trong cùng một group sẽ được dùng chung quyền được cấp.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Tạo và xóa S3 Bucket Sử dụng SNS amazon Tạo IAM group, user và thêm user Tạo và xóa acess key Tạo và cấu hình cơ bản VPS Chạy và chấm dứt EC2 Nắm được cách quản lý và giám sát chi phí trên AWS thông qua các công cụ:\nTạo và cấu hình các gói Budget (Cost, Usage, RI, Savings Plan). Biết cách dọn dẹp tài nguyên để quản lý chi phí hiệu quả. Hiểu về các gói hỗ trợ của AWS và biết cách tạo yêu cầu hỗ trợ từ trung tâm hỗ trợ.\nBasic: Miễn phí, hỗ trợ các vấn đề liên quan đến tài khoản và thanh toán từ trung tâm trợ giúp Developer: 29 USD/tháng, tư vấn kiến trúc cơ bản, và hỗ trợ kỹ thuật không giới hạn được tạo từ tài khoản gốc (root user) Business:100 USD/tháng, lựa chọn phổ biến cho các doanh nghiệp vừa và nhỏ với các hỗ trợ như: Chỉ dẫn theo Use-case cụ thể, Hỗ trợ sử dụng AWS Support API, không giới hạn các yêu cầu hỗ trợ được tạo bởi tất cả các IAM User,\u0026hellip; Enterprise: 15.000 USD/tháng, cho doanh nghiệp quy mô lớn được đảm bảo các tiêu chí bảo mẩ tiêu chuẩn và nghiêm ngặt nhất với các dịch vụ bảo mật như: về kiến trúc phần mềm, hạ tầng, hỗ trợ toàn diện về chiến lược và tối ưu chi phí, được ưu tiên chăm sóc đặc biệt các yêu cấu hỗ trợ,\u0026hellip; Làm quen với giao diện AWS Console và sử dụng tốt các thao tác cơ bản qua cả Console và CLI.\n"
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2: Hiểu khái niệm Amazon Virtual Private Cloud (VPC) và tầm quan trọng của nó trong kiến trúc AWS. Biết cách thiết kế, triển khai và quản lý mạng riêng ảo trên AWS. Học cách thiết lập kết nối AWS Site-to-Site VPN giữa môi trường On-Premise và AWS Cloud. Nắm được các phương pháp bảo mật mạng tốt nhất theo chuẩn AWS Well-Architected Framework. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tổng quan về Amazon VPC - Tìm hiểu kiến trúc mạng AWS và vai trò của VPC trong môi trường đám mây - Nắm các khái niệm: Subnet, Route Table, Internet Gateway, NAT Gateway, VPC Peering 15/09/2025 15/09/2025 cloudjourney.awsstudygroup.com 3 - Thực hành: + Tạo VPC với cấu trúc mạng chuẩn + Tạo các Public và Private Subnet + Cấu hình Route Table và Internet Gateway để kết nối Internet 16/09/2025 16/09/2025 cloudjourney.awsstudygroup.com 4 - Tìm hiểu về Network Security trên AWS + Security Groups + Network ACLs + So sánh và thực hành thiết lập quy tắc truy cập - Thực hành: + Tạo Security Group và Network ACL cho VPC + Kiểm thử truy cập bằng EC2 Instance 17/09/2025 17/09/2025 cloudjourney.awsstudygroup.com 5 - Giới thiệu AWS Site-to-Site VPN - Tìm hiểu mô hình kết nối giữa On-premise và AWS Cloud - Thực hành: + Tạo Virtual Private Gateway (VGW) và Customer Gateway (CGW) + Thiết lập kết nối VPN giữa hai môi trường + Kiểm tra trạng thái kết nối và định tuyến 18/09/2025 18/09/2025 cloudjourney.awsstudygroup.com 6 - Tổng kết và đánh giá kết quả học tập tuần 2 - Thực hành nâng cao: + Thiết kế VPC theo chuẩn AWS Well-Architected Framework + Tự động hóa triển khai hạ tầng bằng Infrastructure as Code (IaC) template (CloudFormation hoặc Terraform) + Dọn dẹp tài nguyên sau khi hoàn thành workshop 19/09/2025 19/09/2025 cloudjourney.awsstudygroup.com Kết quả đạt được tuần 2: Hiểu rõ Amazon VPC là gì và tầm quan trọng của việc cô lập mạng trong AWS Cloud.\nNắm được cấu trúc cơ bản của một VPC bao gồm:\nSubnets: Phân chia vùng mạng cho tài nguyên. Route Tables: Định tuyến lưu lượng mạng trong VPC. Internet Gateway: Cho phép kết nối từ VPC ra Internet. NAT Gateway: Cho phép các instance trong subnet riêng kết nối Internet an toàn. VPC Peering: Kết nối hai VPC khác nhau để chia sẻ tài nguyên. Thực hành triển khai thành công VPC với các subnet riêng và công khai, kiểm tra kết nối thông qua EC2 Instance.\nHiểu và cấu hình thành công Security Groups và Network ACLs, phân biệt được phạm vi áp dụng của từng loại bảo mật mạng.\nNắm được quy trình thiết lập Site-to-Site VPN giữa hệ thống tại chỗ (on-premise) và AWS:\nTạo và cấu hình Virtual Private Gateway (VGW) và Customer Gateway (CGW). Kết nối hai đầu VPN bằng các thông số định tuyến (tunnel configuration). Kiểm tra kết nối VPN bằng lệnh CLI và bảng điều khiển AWS Console. Nắm được các phương pháp bảo mật mạng nâng cao theo chuẩn AWS Well-Architected Framework, bao gồm:\nPhân đoạn mạng (Network Segmentation). Kiểm soát truy cập ở cấp subnet và instance. Mã hóa dữ liệu trong quá trình truyền tải qua VPN. Làm quen với cách triển khai Infrastructure as Code (IaC) để tự động hóa việc tạo VPC, Subnet, Route Table và Security Groups.\nHoàn thành workshop:\nThiết kế và triển khai mô hình VPC hoàn chỉnh. Thiết lập thành công Site-to-Site VPN. Dọn dẹp toàn bộ tài nguyên sau khi hoàn tất. Tóm tắt kiến thức đạt được: Amazon VPC: Nắm rõ mô hình mạng riêng ảo trong AWS. Network Security: Biết cấu hình và kiểm soát truy cập hiệu quả bằng Security Group \u0026amp; Network ACL. VPN Connection: Hiểu cách thiết lập và vận hành kết nối Site-to-Site an toàn. AWS CLI \u0026amp; Console: Thực hành triển khai, kiểm tra và dọn dẹp tài nguyên qua cả hai công cụ. IaC (Infrastructure as Code): Làm quen với việc tự động hóa triển khai hạ tầng AWS. "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 3: Hiểu khái niệm và chức năng của Amazon EC2 (Elastic Compute Cloud). Học cách khởi tạo, kết nối, cấu hình và quản lý các EC2 instance trên cả Windows và Linux. Thực hành triển khai một ứng dụng web mẫu (AWS User Management) trên các EC2 instance. Học cách giám sát, bảo mật và dọn dẹp tài nguyên EC2 một cách hiệu quả. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tổng quan về Amazon EC2 và các khái niệm chính: + Instance, AMI, Key Pair, Elastic IP, Security Group, Volume + Các mô hình tính phí của EC2 (On-Demand, Spot, Reserved, Savings Plan) 22/09/2025 22/09/2025 cloudjourney.awsstudygroup.com 3 - Thực hành: Tạo và cấu hình Windows EC2 instance + Chọn AMI và loại instance + Cấu hình key pair và security group + Kết nối bằng Remote Desktop (RDP) + Khám phá môi trường Windows Server 2022 23/09/2025 23/09/2025 cloudjourney.awsstudygroup.com 4 - Thực hành: Tạo và cấu hình Linux EC2 instance + Khởi tạo Amazon Linux 2 + Kết nối qua SSH bằng key pair + Làm quen với môi trường Linux và các lệnh cơ bản + Cập nhật gói hệ thống 24/09/2025 24/09/2025 cloudjourney.awsstudygroup.com 5 - Triển khai ứng dụng mẫu “AWS User Management” + Cài đặt Node.js, npm và các thư viện cần thiết trên cả Linux và Windows instance + Triển khai ứng dụng CRUD (User Management System) + Kiểm thử các chức năng: thêm, sửa, xóa, tìm kiếm người dùng + Chia sẻ ứng dụng qua mạng bằng Security Group 25/09/2025 25/09/2025 cloudjourney.awsstudygroup.com 6 - Tìm hiểu công cụ giám sát và quản lý EC2: + Amazon CloudWatch (giám sát chỉ số và nhật ký) + AWS Systems Manager + EC2 Instance Connect - Dọn dẹp các instance, Elastic IP và Security Group không sử dụng 26/09/2025 26/09/2025 cloudjourney.awsstudygroup.com Kết quả đạt được trong tuần 3: Hiểu rõ các khái niệm cốt lõi của Amazon EC2, bao gồm:\nAMI (Amazon Machine Image): Cung cấp hệ điều hành và mẫu ứng dụng để khởi tạo instance. Instance Type: Xác định tài nguyên tính toán (CPU, RAM, bộ nhớ). Key Pair: Dùng để đăng nhập an toàn (SSH/RDP). Elastic IP: Địa chỉ IP tĩnh cho phép truy cập instance qua Internet. Security Group: Tường lửa ảo kiểm soát lưu lượng vào/ra. Tạo và cấu hình thành công Windows và Linux EC2 instance:\nKết nối qua RDP (Windows) và SSH (Linux). Quản lý instance thông qua AWS Console và CLI. Cấu hình quy tắc mạng cho phép truy cập web (port 80, 443, 22, 3389). Triển khai thành công ứng dụng AWS User Management trên cả hai nền tảng:\nCài đặt Node.js, npm và các thư viện phụ thuộc. Triển khai ứng dụng CRUD đầy đủ (Thêm, Sửa, Xóa, Tìm kiếm người dùng). Chia sẻ ứng dụng cho người dùng khác thông qua Public IP hoặc Elastic IP. Học cách giám sát EC2 instance bằng:\nAmazon CloudWatch (giám sát CPU, bộ nhớ, lưu lượng mạng). AWS Systems Manager để tự động hóa và quản lý instance. EC2 Instance Connect để truy cập an toàn qua trình duyệt. Thực hành quản lý tài nguyên và tối ưu chi phí:\nDừng hoặc xóa các instance không còn sử dụng. Giải phóng Elastic IP chưa dùng. Xóa các Security Group và Key Pair dư thừa. Tóm tắt kiến thức đạt được: Amazon EC2: Hiểu sâu về cách vận hành máy chủ ảo trong môi trường đám mây. Quản lý Windows \u0026amp; Linux: Thực hành cấu hình, kết nối và bảo mật trên cả hai hệ điều hành. Triển khai ứng dụng: Triển khai thành công ứng dụng Node.js CRUD trên EC2. Giám sát hệ thống: Sử dụng CloudWatch và Systems Manager để theo dõi hiệu suất. Tối ưu chi phí: Biết cách dọn dẹp và quản lý tài nguyên EC2 hiệu quả. "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4 Hiểu rõ cơ chế cấp quyền truy cập cho ứng dụng sử dụng dịch vụ AWS. Nắm được sự khác biệt giữa Access Key/Secret Access Key và IAM Role. Biết cách tạo và gán IAM Role cho EC2 Instance để ứng dụng có thể truy cập dịch vụ AWS mà không cần lưu trữ thông tin xác thực. Làm quen và thực hành với AWS Cloud9, môi trường IDE trên trình duyệt được tích hợp sẵn AWS CLI. Học cách viết, chạy, và kiểm thử mã nguồn trực tiếp trong Cloud9. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tổng quan về AWS Identity and Access Management (IAM) - Tìm hiểu cách AWS kiểm soát truy cập vào tài nguyên - Ôn lại khái niệm User, Group, Policy, Role 22/09/2025 22/09/2025 cloudjourney.awsstudygroup.com 3 - Thực hành cấp quyền bằng Access Key và Secret Access Key - Chạy thử ứng dụng truy cập dịch vụ AWS qua Access Key - Phân tích rủi ro bảo mật khi lưu trữ Access Key trong mã nguồn 23/09/2025 23/09/2025 cloudjourney.awsstudygroup.com 4 - Giới thiệu và tạo IAM Role cho EC2 Instance - Gán IAM Role cho instance và kiểm tra quyền truy cập đến S3/DynamoDB qua ứng dụng Node.js mẫu - Thực hành thu hồi quyền truy cập và kiểm thử lại ứng dụng 24/09/2025 24/09/2025 cloudjourney.awsstudygroup.com 5 - Làm quen với AWS Cloud9 IDE - Tạo một Cloud9 instance và thiết lập môi trường làm việc - Khám phá các tính năng: terminal, file explorer, debugger, syntax highlighting 25/09/2025 25/09/2025 cloudjourney.awsstudygroup.com 6 - Thực hành nâng cao: + Viết script truy cập dịch vụ AWS bằng AWS CLI trên Cloud9 + Triển khai ứng dụng Node.js CRUD (AWS User Management) trực tiếp trên Cloud9 + Dọn dẹp tài nguyên sau khi hoàn thành 26/09/2025 26/09/2025 cloudjourney.awsstudygroup.com Kết quả đạt được trong tuần 4 : Hiểu rõ sự khác biệt giữa Access Key/Secret Key và IAM Role, và lý do nên sử dụng IAM Role để tăng cường bảo mật. Biết cách tạo IAM Role với quyền hạn phù hợp (ví dụ: quyền đọc/ghi S3). Gán IAM Role cho EC2 Instance và kiểm tra truy cập dịch vụ AWS trực tiếp mà không cần thông tin đăng nhập tĩnh. Làm quen và sử dụng thành thạo AWS Cloud9 IDE: Tạo và cấu hình môi trường phát triển. Kết nối với EC2 instance. Chạy các lệnh AWS CLI và thử nghiệm mã nguồn trực tiếp. Viết và triển khai ứng dụng Node.js đơn giản trên Cloud9 để truy cập dữ liệu từ AWS S3 hoặc DynamoDB. Nắm được quy trình dọn dẹp tài nguyên sau khi thực hành để tránh phát sinh chi phí. Tóm tắt kiến thức đạt được IAM Role: Giải pháp bảo mật tốt hơn Access Key, cho phép cấp quyền tạm thời cho EC2. Access Key/Secret Key: Hiểu rõ nhược điểm khi sử dụng trong mã nguồn. AWS Cloud9: IDE mạnh mẽ chạy trên trình duyệt, hỗ trợ nhiều ngôn ngữ lập trình và tích hợp CLI. AWS CLI \u0026amp; SDK: Sử dụng để truy cập dịch vụ AWS thông qua vai trò IAM. Thực hành triển khai: Cấu hình, chạy và dọn dẹp môi trường AWS an toàn, hiệu quả. "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Hiểu sâu về Amazon S3 — mô hình object storage, các tính năng chính và các trường hợp sử dụng. Thực hành host static website trên S3: kích hoạt tính năng, cấu hình public access, kiểm tra và tối ưu hiệu năng. Học cách bảo mật bucket (Block Public Access, IAM policy, Bucket Policy) đồng thời cho phép public object khi cần. Thực hiện các thao tác quản lý nâng cao: Versioning, S3 Transfer Acceleration, S3 Batch / S3 Replication (sao chép sang region khác), di chuyển object. Biết cách dọn dẹp tài nguyên để tránh phát sinh chi phí và nắm được các best practices khi dùng S3. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 Chuẩn bị môi trường \u0026amp; lý thuyết cơ bản + Tổng quan S3: object, bucket, key, region, storage class (STANDARD, IA, GLACIER) + Độ bền \u0026amp; tính sẵn sàng (11 nines) + Trường hợp sử dụng (static website, backup, data lake) 06/10/2025 06/10/2025 cloudjourney.awsstudygroup.com 3 Tạo bucket S3 \u0026amp; bật Static Website Hosting + Tạo bucket (quy tắc đặt tên, chọn region) + Tải file index.html / error.html lên bucket + Bật Static website hosting và lấy endpoint để kiểm tra 07/10/2025 07/10/2025 cloudjourney.awsstudygroup.com 4 Cấu hình Block Public Access \u0026amp; Public Object + Bucket Policy + Hiểu các thiết lập Block Public Access ở cấp tài khoản và bucket + Cấu hình Bucket Policy cho phép truy cập công khai chỉ với object cụ thể (index.html) + Kiểm tra truy cập từ trình duyệt + Thực hành dọn dẹp quyền public và xác minh bảo mật 08/10/2025 08/10/2025 cloudjourney.awsstudygroup.com 5 Tăng tốc Static Website \u0026amp; Bảo mật nâng cao + So sánh dùng S3 + CloudFront vs S3 Transfer Acceleration vs AWS Amplify Hosting + Thực hành bật S3 Transfer Acceleration và kiểm nghiệm tốc độ (curl thử từ nhiều vùng) + (Tuỳ chọn) Tạo CloudFront distribution trỏ tới S3 để bật HTTPS và CDN + Tích hợp giám sát bằng CloudWatch và theo dõi chi phí 09/10/2025 09/10/2025 cloudjourney.awsstudygroup.com 6 Versioning, Lifecycle \u0026amp; Replication + Dọn dẹp tài nguyên + Bật Bucket Versioning, thử overwrite và khôi phục version cũ + Thiết lập lifecycle rules: chuyển object sang IA/Glacier sau N ngày + Cấu hình S3 Replication (CRR) sao chép sang region khác, tạo IAM role phù hợp + Di chuyển object giữa bucket/region (copy, move, sync) + Dọn dẹp tài nguyên: xóa object, tắt transfer acceleration, gỡ CloudFront (nếu có), xóa bucket thử nghiệm 10/10/2025 10/10/2025 cloudjourney.awsstudygroup.com Kết quả đạt được trong tuần 5: Cấu hình và thao tác cơ bản:\nThiết lập và cấu hình AWS CLI để làm việc với Amazon S3 (Access Key, Secret Key, Region mặc định). Kiểm tra kết nối và thông tin cấu hình bằng các lệnh: aws configure list aws s3 ls để liệt kê bucket hiện có. aws s3api list-buckets để lấy thông tin chi tiết bucket. Tạo và xóa bucket qua CLI: aws s3 mb s3://ten-bucket aws s3 rb s3://ten-bucket --force Thực hành Static Website Hosting:\nTạo bucket mới, upload index.html và error.html. Bật Static Website Hosting và truy cập được website qua endpoint công khai. Kiểm tra lỗi 403/404 khi truy cập sai đường dẫn, xác minh error.html hoạt động đúng. Thiết lập bảo mật và quyền truy cập:\nBật và tắt Block Public Access ở cả cấp tài khoản và bucket để hiểu cơ chế. Cấu hình Bucket Policy cho phép public duy nhất object index.html. Thử public và private object để kiểm tra chính xác quyền truy cập. Quản lý dữ liệu và tối ưu hiệu năng:\nBật Versioning trên bucket, upload nhiều version cho cùng object, và thực hành khôi phục version cũ. Thiết lập Lifecycle Rules để chuyển object ít truy cập sang lớp lưu trữ IA hoặc Glacier. Thử S3 Transfer Acceleration và đo sự khác biệt tốc độ upload từ các region khác nhau bằng curl. Quản lý nâng cao và di chuyển dữ liệu:\nCấu hình Cross-Region Replication (CRR) để sao chép object sang bucket ở region khác, hiểu vai trò của IAM Role (Replication Role). Dùng các lệnh CLI: aws s3 cp, aws s3 mv, aws s3 sync để di chuyển hoặc đồng bộ dữ liệu giữa các bucket. Kiểm tra và xác nhận object replicated thành công trên bucket đích. Dọn dẹp \u0026amp; tối ưu chi phí:\nXóa toàn bộ object test, tắt Transfer Acceleration và CloudFront (nếu dùng). Tắt hosting hoặc xóa bucket thử nghiệm để tránh phát sinh chi phí. Tổng hợp best practices: Không public toàn bộ bucket. Dùng Versioning + Lifecycle để tiết kiệm chi phí. Giám sát dung lượng qua S3 Storage Lens và đặt budget alert qua CloudWatch. Ghi chú : Không để bucket public toàn bộ trừ khi thật sự cần; dùng Bucket Policy để chỉ public object cụ thể (index.html). Bật Block Public Access ở cấp tài khoản để tránh mở nhầm; vượt qua Block Public Access chỉ khi bạn hiểu rõ rủi ro. Dùng Versioning + Lifecycle: versioning giúp khôi phục nhầm lẫn; lifecycle rules giúp tự động chuyển dữ liệu sang lớp rẻ hơn (IA/Glacier). Sử dụng CloudFront nếu cần HTTPS, custom domain hoặc tối ưu hiệu năng toàn cầu; S3 Transfer Acceleration phù hợp khi upload/ download từ client ở xa cần tăng tốc — nhưng chi phí có thể cao hơn. AWS Amplify Hosting là lựa chọn hiện đại, tự động hóa deploy từ repo, cung cấp HTTPS mặc định và CDN — dùng nếu bạn host site tĩnh mà muốn ít cấu hình. Bảo mật: sử dụng IAM policy chặt chẽ, tránh chèn Access Key trong mã nguồn; sử dụng IAM Role cho EC2 / Lambda. Theo dõi \u0026amp; Báo cáo chi phí: bật CloudWatch + S3 Storage Lens, và tạo budget để tránh phát sinh chi phí bất ngờ. Kiểm thử trước khi xóa: khi xóa bucket có Versioning, cần xóa mọi versions \u0026amp; delete markers, chú ý chi phí chuyển dữ liệu khi replicate hoặc restore từ Glacier. Tóm tắt kiến thức đạt được: Vận hành S3 ở mức production: hosting, bảo mật, tối ưu chi phí, versioning và replication. Lựa chọn công cụ tối ưu cho hosting static site: Amplify (khuyến nghị), CloudFront + S3 hoặc S3 (đơn giản) tùy nhu cầu. Thực hiện các tác vụ quản lý dữ liệu lớn: di chuyển, sao chép sang region khác, và tự động hoá bằng lifecycle rules. Biết dọn dẹp an toàn và tối ưu để tránh chi phí phát sinh không mong muốn. "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 6 : Hiểu kiến trúc Amazon RDS và các engine được hỗ trợ (MySQL, PostgreSQL, MariaDB, SQL Server…). Tạo, cấu hình và quản lý một RDS Instance ở mức nền tảng. Thiết lập parameter group, security group, subnet group dành cho RDS. Kết nối RDS từ EC2, Cloud9, và từ máy local. Thực hành backup – restore – snapshot – automated backup – failover. Làm quen với Performance Insights, Monitoring, Enhanced Logging. Biết cách tối ưu chi phí, scale storage và compute, và dọn dẹp tài nguyên. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 Tổng quan Amazon RDS + Các engine hỗ trợ + Kiến trúc Multi-AZ \u0026amp; Read Replica + Backup/Snapshot lifecycle 13/10/2025 13/10/2025 cloudjourney.awsstudygroup.com 3 Tạo RDS Instance + Tạo Subnet Group + Cấu hình Security Group (cho phép EC2/Cloud9) + Chọn engine, size, storage 14/10/2025 14/10/2025 cloudjourney.awsstudygroup.com 4 Kết nối \u0026amp; thao tác trên RDS + Kết nối từ Cloud9/EC2 + Tạo database \u0026amp; table + CRUD bằng MySQL Client hoặc PostgreSQL Client 15/10/2025 15/10/2025 cloudjourney.awsstudygroup.com 5 Backup – Restore – Snapshot – Monitoring + Tạo snapshot thủ công + Restore từ snapshot + Quan sát monitoring, CPU, connections + Sử dụng Performance Insights 16/10/2025 16/10/2025 cloudjourney.awsstudygroup.com 6 Scaling – Tối ưu chi phí – Dọn dẹp tài nguyên + Thay đổi instance class + Mở rộng storage + Cấu hình tự động backup hợp lý + Xóa snapshot \u0026amp; RDS để tránh phát sinh chi phí 17/10/2025 17/10/2025 cloudjourney.awsstudygroup.com Kết quả đạt được trong tuần 6: 1. Hiểu rõ kiến trúc Amazon RDS:\nPhân biệt được: Single-AZ, Multi-AZ, Read Replica. Biết cách hoạt động của automated backup (giữ 1–35 ngày). Biết snapshot là backup thủ công, không tự xóa. 2. Tạo và cấu hình RDS Instance hoàn chỉnh:\nTạo DB Subnet Group chứa 2 subnet ở 2 AZ. Tạo Security Group cho phép kết nối từ EC2/Cloud9 (port 3306 hoặc 5432). Cấu hình instance với: Engine (MySQL/PostgreSQL) Instance class (db.t3.micro) Storage (20GB gp3) Backup retention Public/Private endpoint 3. Kết nối thành công từ EC2 / Cloud9 / local: Cài đặt MySQL/PostgreSQL client. Kết nối bằng chuỗi: mysql -h endpoint.amazonaws.com -u admin -p Tạo database, table và CRUD dữ liệu: CREATE DATABASE demo; CREATE TABLE users (...); INSERT, SELECT, UPDATE, DELETE 4. Làm chủ Backup – Restore – Snapshot:\nTạo manual snapshot. Restore thành RDS mới từ snapshot. Quan sát backup window. Kiểm tra automated backups tạo tự động mỗi ngày. 5. Monitoring \u0026amp; Performance:\nTheo dõi CPU, RAM, active connections trong “Monitoring”. Sử dụng Performance Insights xem truy vấn nặng. Xem Slow Query Log (nếu bật). 6. Scaling \u0026amp; Tối ưu chi phí:\nThay đổi instance class từ t3.micro → t3.small. Tăng storage từ 20GB → 30GB. Giảm backup retention xuống 3 ngày để giảm chi phí. Xóa snapshot không cần thiết. 7. Dọn dẹp tài nguyên để tránh phát sinh chi phí:\nXóa RDS instance. Xóa subnet group. Xóa security group. Xóa snapshot cũ. Tóm tắt kiến thức đạt được Hiểu cách RDS hoạt động và các engine phổ biến. Biết tạo, cấu hình và kết nối tới RDS từ Cloud9 và EC2. Nắm được cơ chế backup, snapshot, restore. Sử dụng Performance Insights để theo dõi hiệu năng. Biết cách scale và tối ưu chi phí RDS. Dọn dẹp tài nguyên đúng cách để tránh lệ phí cao. "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần : Phần 1 – AWS CloudWatch\nHiểu tổng quan kiến trúc Amazon CloudWatch và các thành phần: Metrics, Logs, Alarms, Dashboard, Events. Thực hành tạo và giám sát CloudWatch Metrics cho EC2, RDS, Lambda. Thu thập và phân tích logs với CloudWatch Logs. Tạo CloudWatch Alarm với các ngưỡng tùy chỉnh. Xây dựng CloudWatch Dashboard theo dõi hệ thống. Thực hành container monitoring với CloudWatch Container Insights. Dọn dẹp tài nguyên tránh phát sinh chi phí. Phần 2 – Hybrid DNS với Route 53 Resolver\nHiểu kiến trúc DNS hybrid giữa on-premise và AWS. Tạo và cấu hình Route 53 Resolver (inbound, outbound). Tạo và áp dụng Resolver Rules để forward DNS query. Tích hợp DNS on-premise (Active Directory DNS) với Route 53 private hosted zone. Kiểm tra phân giải tên miền 2 chiều (AWS → on-premise, on-premise → AWS). Dọn dẹp tài nguyên: AD, endpoint, VPC config. Các công việc triển khai trong tuần Thứ Công việc chi tiết Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 CloudWatch – Tổng quan \u0026amp; Kiến trúc • Nghiên cứu tổng quan CloudWatch và vai trò trong hệ thống AWS. • Tìm hiểu các thành phần chính: Metrics, Logs, Alarms, Dashboards, Events, Container Insights. • Hiểu sự khác biệt giữa Basic Monitoring và Detailed Monitoring. • Xem kiến trúc CloudWatch end-to-end: ứng dụng → log agent → log group → metric filter → alarm → SNS → hành động tự động. • Tạo biểu đồ đầu tiên từ metrics mặc định của EC2. 20/10/2025 20/10/2025 cloudjourney.awsstudygroup.com 3 CloudWatch Metrics \u0026amp; Logs – Triển khai thực tế • Tạo Log Group thủ công và tìm hiểu cấu trúc Log Stream. • Cài đặt CloudWatch Agent lên EC2 để thu thập CPU, RAM, Disk, Network ở mức OS-level. • Cấu hình file cloudwatch-agent.json để gửi logs hệ thống (syslog, application log). • Tạo Metric Filter để tìm lỗi theo pattern (“ERROR”, “CRITICAL”, “Failed”). • Gửi custom metric bằng lệnh AWS CLI (put-metric-data). • Quan sát retention period và test thay đổi retention. 21/10/2025 21/10/2025 cloudjourney.awsstudygroup.com 4 CloudWatch Alarm \u0026amp; Dashboard – Tự động hóa cảnh báo • Tạo CPU Alarm với ngưỡng 70% trong 5 phút. • Tạo Alarm cho EC2 Status Check Failure. • Kết nối Alarm → SNS Topic → Email để nhận cảnh báo. • Tạo Alarm tự động reboot EC2 khi CPU quá tải (bằng EC2 action). • Tạo Dashboard tùy chỉnh: thêm widget metrics, logs, alarm status, text widget. • Tạo Dashboard giám sát toàn bộ hệ thống: EC2 + RDS + Network. • Thực hiện Container Insights cho ECS: xem CPU, RAM, Task Restart. 22/10/2025 22/10/2025 cloudjourney.awsstudygroup.com 5 Route 53 Resolver – Hiểu và xây dựng kiến trúc DNS Hybrid • Tìm hiểu Route 53 private hosted zone và DNS resolution trong VPC. • Tạo Outbound Resolver Endpoint để AWS gửi truy vấn về on-premise DNS. • Tạo Inbound Resolver Endpoint cho phép hệ thống on-premise truy vấn ngược lên AWS. • Tạo Resolver Rule chuyển tiếp tên miền “corp.local” về DNS on-premise. • Gán rules vào VPC và kiểm tra trạng thái endpoint. 23/10/2025 23/10/2025 cloudjourney.awsstudygroup.com 6 Microsoft AD + DNS Integration – Mô phỏng on-premise DNS • Khởi tạo EC2 Windows Server và cài đặt Microsoft Active Directory. • Tạo domain “corp.local” và cấu hình DNS zone trong AD. • Cấu hình Conditional Forwarder từ AD → Inbound Endpoint AWS. • Tạo bản ghi A, CNAME trong on-premise DNS. • Kiểm tra phân giải 2 chiều: – Từ AWS: nslookup dc1.corp.local – Từ AD: nslookup api.internal.aws • Kiểm tra phân giải khi endpoint down (test failover). 24/10/2025 24/10/2025 cloudjourney.awsstudygroup.com 7 Dọn dẹp tài nguyên, review và tối ưu chi phí • Xóa Log Group, Log Stream, Alarm, Dashboard không dùng. • Tắt Container Insights để tránh phí CloudWatch. • Xóa Route 53 Resolver endpoints (vì tính theo giờ). • Xóa Resolver Rule. • Tắt và xóa Microsoft AD domain controller. • Xóa toàn bộ EC2 test. • Kiểm tra Bill → xem phần CloudWatch Logs, metrics, AD, endpoints. 25/10/2025 25/10/2025 cloudjourney.awsstudygroup.com Kết quả đạt được trong tuần 7: 1. AWS CloudWatch CloudWatch Metrics – Thu thập \u0026amp; phân tích\nLiệt kê toàn bộ metrics mặc định từ EC2, EBS, VPC, ELB. Tự tạo custom metrics bằng CLI và PutMetricData. Kiểm tra retention 15 tháng, xem thử biểu đồ theo 1s granularity. Phân tích các tình huống bất thường: CPU Spike, Network I/O tăng đột biến, DiskOps cao. CloudWatch Logs – Thu thập log ứng dụng\nCài đặt CloudWatch Agent để thu thập log OS và ứng dụng. Tạo Log Group, Log Stream, đẩy dữ liệu real-time. Thiết lập log retention, export logs ra S3 để phân tích. Nhận diện các lỗi phổ biến trong log: throttling, unauthorized, lỗi CPUCredit. CloudWatch Alarms – Cảnh báo và phản hồi\nTạo alarm cho CPU \u0026gt; 70% trong 3 phút. Tạo alarm cho trạng thái hệ thống EC2 fail. Thiết lập SNS notification để gửi email cảnh báo. Thiết lập auto-recovery khi EC2 bị lỗi phần cứng. CloudWatch Dashboard – Bảng điều khiển giám sát\nTự xây dựng dashboard theo dạng real-time. Gắn metrics của EC2, RDS, NAT Gateway, ELB lên cùng một giao diện. Tích hợp widget dạng graph, single value và log pattern. Container Insights – Giám sát microservices\nBật CloudWatch Container Insights cho ECS \u0026amp; Fargate. Giám sát CPU/memory per task, per pod, per container. Phân tích lỗi container restart count để xác định root cause. Đánh giá cách CloudWatch Insight hỗ trợ troubleshooting nhanh. Dọn dẹp tài nguyên\nXóa Dashboard, Alarm, Metrics custom. Dừng agent và xoá log group. Tắt Container Insights để tránh phát sinh phí. Kết quả đạt được\nNắm vững kiến trúc CloudWatch và pipeline giám sát toàn hệ thống AWS. Tự triển khai đầy đủ quy trình monitoring: metrics → logs → alarm → dashboard. Biết phân tích và xử lý lỗi dựa trên logs và metrics. Thành thạo hơn trong việc tối ưu hoá chi phí và hiệu năng nhờ dữ liệu CloudWatch. Có khả năng xây dựng hệ thống cảnh báo real-time phục vụ DevOps / SRE. 2. Thiết lập Hybrid DNS với Route 53 Resolver Tìm hiểu kiến trúc Hybrid DN\nPhân tích vấn đề thường gặp khi doanh nghiệp có DNS on-prem. Hiểu vai trò của: Inbound Endpoint (on-prem → AWS) Outbound Endpoint (AWS → on-prem) Resolver Rules để forward tên miền nội bộ. Chuẩn bị môi trường\nTạo 1 VPC riêng với 2 private subnet để đặt endpoint. Tạo Security Group cho DNS với port 53 UDP/TCP. Deploy 1 EC2 Windows Server để chạy Microsoft Active Directory Domain Services. Kết nối đến RDGW (Remote Desktop Gateway)\nKết nối qua RDGW để truy cập server trong private subnet. Kiểm tra khả năng phân giải DNS trong VPC trước khi cấu hình hybrid. Triển khai Microsoft Active Directory\nCấu hình Domain Controller on-prem (giả lập). Thiết lập DNS internal zone: ví dụ company.local. Kiểm tra bản ghi SRV, A, NS hoạt động đúng. Thiết lập hệ thống DNS Hybrid\n1) Outbound Endpoint\nTạo Outbound Endpoint để EC2 trong VPC có thể gửi DNS query về AD on-prem. Gán các resolver rule forward domain company.local về IP DNS on-prem. 2) Inbound Endpoint\nTạo Inbound Endpoint để DNS on-prem có thể truy cập Private Hosted Zone của AWS. Kiểm tra khả năng phân giải record trong Route 53 Private Zone. 3) Resolver Rules\nTạo rule kiểu Forwarding cho domain nội bộ. Tạo rule kiểu System để tự động nhận DNS mặc định của VPC. Kiểm thử toàn bộ luồng DNS\nTừ server on-prem: ping DNS record của Private Hosted Zone → thành công. Từ EC2 trên AWS: phân giải tên miền on-prem → thành công. Kiểm tra độ trễ DNS và xác thực 2-way resolution. Dọn dẹp tài nguyên\nXóa endpoint để tránh phát sinh chi phí theo giờ. Xóa Private Hosted Zone và các test records. Gỡ AD và tắt EC2 test. Kết quả đạt được\nHiểu rõ cơ chế vận hành DNS hybrid trong doanh nghiệp. Tự triển khai hệ thống Route 53 Resolver hoàn chỉnh (inbound, outbound, rules). Tích hợp thành công DNS Microsoft AD với DNS của AWS. Kiểm tra thành công luồng phân giải DNS hai chiều. Nắm chắc mô hình DNS hiện đại cho môi trường multi-cloud và hybrid-cloud. Tóm tắt kiến thức đạt được CloudWatch:\nThu thập metrics, logs end-to-end. Tạo alarms thông minh và tự động hóa xử lý. Xây dashboard trực quan. Giám sát container bằng Container Insights. Route 53 Hybrid DNS:\nHiểu mô hình DNS hybrid thực tế. Tích hợp on-premise DNS với Route 53 Resolver. Kiểm tra phân giải 2 chiều giữa hệ thống. Áp dụng vào triển khai hệ thống doanh nghiệp. "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần : Phần 1 – Amazon DynamoDB\nHiểu kiến trúc NoSQL key-value \u0026amp; document của DynamoDB. Nắm các thành phần: Partition Key, Sort Key, Partition, RCU/WCU, On-Demand, TTL, Streams, Global Tables. Tạo bảng DynamoDB với GSI/LSI và định nghĩa Access Pattern. Thực hành CRUD: PutItem, GetItem, UpdateItem, DeleteItem. Thực hành Query \u0026amp; Scan, FilterExpression, ConditionExpression. Dùng AWS CLI và JSON để tương tác DynamoDB. Import dataset thử nghiệm vào DynamoDB. Phần 2 – Amazon ElastiCache for Redis\nHiểu cấu trúc in-memory caching, cluster mode enabled/disabled. Tạo Redis Cluster trong VPC: node, parameter group, subnet group. Kết nối Redis từ EC2 qua redis-cli. Thử nghiệm dữ liệu: SET, GET, TTL \u0026amp; persistence snapshot. Áp dụng mô hình Cache-Aside giữa Redis \u0026amp; DynamoDB. Kiểm tra hiệu năng cache-hit và cache-miss. Dọn dẹp tài nguyên để tránh chi phí. Các công việc triển khai trong tuần Thứ Công việc chi tiết Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 DynamoDB – Tổng quan \u0026amp; Kiến trúc • Tìm hiểu DynamoDB là NoSQL key-value/document. • Hiểu kiến trúc partition, phân phối dữ liệu theo Partition Key. • Hiểu WCU/RCU, Auto Scaling, On-Demand. • Nắm vai trò GSI/LSI và các access pattern phổ biến. • Tìm hiểu TTL \u0026amp; Streams. 27/10/2025 27/10/2025 cloudjourney.awsstudygroup.com 3 Tạo DynamoDB Table \u0026amp; Query thực tế • Tạo bảng với Partition Key + Sort Key. • Tạo nhóm GSI để mở rộng truy vấn. • Bật TTL và test bản ghi hết hạn. • Thực hành CRUD (Put/Get/Update/Delete). • Thực hành Query vs Scan, FilterExpression, ProjectionExpression. 28/10/2025 28/11/2025 cloudjourney.awsstudygroup.com 4 Thao tác DynamoDB bằng AWS CLI • Tạo bảng DynamoDB bằng CLI. • Import file JSON mẫu. • Query qua CLI: KeyConditionExpression. • UpdateItem có điều kiện với ConditionExpression. • Quan sát throughput \u0026amp; consumed capacity. 29/10/2025 29/10/2025 cloudjourney.awsstudygroup.com 5 ElastiCache Redis – Kiến trúc \u0026amp; Triển khai • Hiểu kiến trúc in-memory, replication group. • Tạo subnet group và security group cho Redis. • Khởi tạo Redis Cluster 1 primary + replicas. • Kích hoạt Automatic Failover. • Kết nối EC2 vào Redis qua redis-cli. 30/10/2025 30/10/2025 cloudjourney.awsstudygroup.com 6 Redis thực hành nâng cao \u0026amp; tích hợp DynamoDB • Thử GET, SET, EXPIRE, TTL. • Test persistence snapshot (RDB). • Tạo mô hình Cache-Aside: – Cache hit trả về ngay. – Cache miss → đọc từ DynamoDB. – Ghi lại cache Redis để tối ưu hiệu năng. • Kiểm tra độ trễ giữa Redis vs DynamoDB. 31/10/2025 31/10/2025 cloudjourney.awsstudygroup.com 7 Dọn dẹp tài nguyên \u0026amp; Đánh giá hiệu năng • Xóa Redis Cluster, subnet group, parameter group. • Xóa DynamoDB Table test. • Kiểm tra Billing xem phí WCU/RCU phát sinh. • Đánh giá sự khác biệt hiệu năng cache: Redis: ~1–2ms – DynamoDB: ~10–20ms. 1 /11/2025 1 /11/2025 cloudjourney.awsstudygroup.com Kết quả đạt được trong tuần 8: 1. Amazon DynamoDB Kiến trúc \u0026amp; thiết kế bảng\nNắm rõ cơ chế phân vùng, scaling và throughput. Hiểu cách thiết kế Partition Key, Sort Key tránh hotspot. Tối ưu access pattern bằng GSI \u0026amp; LSI. CRUD \u0026amp; Query\nThực hiện đầy đủ CRUD qua Console \u0026amp; CLI. Thành thạo Query theo KeyConditionExpression. Biết sử dụng FilterExpression, UpdateExpression. Scan bảng và lọc dữ liệu nâng cao. Quản lý DynamoDB nâng cao\nBật TTL \u0026amp; kiểm tra cơ chế tự xóa bản ghi. Kiểm tra DynamoDB Streams \u0026amp; kiến trúc event-driven. Đánh giá cost dựa trên RCU/WCU và On-Demand. 2. Amazon ElastiCache for Redis Triển khai Redis Cluster\nTạo Redis trong VPC với subnet group \u0026amp; security group đúng chuẩn. Cấu hình replication group + failover tự động. Kết nối Redis từ EC2 thành công. Thao tác Redis\nThành thạo SET, GET, DEL, TTL, EXPIRE. Test persistence snapshot (RDB). Phân tích eviction policy khi cache đầy. 3. Tích hợp DynamoDB + Redis (Cache-Aside) Xây dựng quy trình: check cache → query DB → cập nhật cache. Thử nghiệm cache hit/miss thực tế. Đo hiệu năng: Redis nhanh gấp ~10 lần DynamoDB. Hiểu lý do phải dùng Redis caching đối với hệ thống đọc nhiều (read-heavy). Biết mô hình ứng dụng thực tế: user profile caching, session store, product caching. Tóm tắt kiến thức đạt được DynamoDB:\nKiến trúc NoSQL phân tán. Partition Key, Sort Key, GSI/LSI. CRUD, Query, Scan. Throughput RCU/WCU \u0026amp; On-Demand. TTL, Streams. ElastiCache Redis:\nKiến trúc in-memory cực nhanh. Cluster mode, replication, failover. TTL, snapshot persistence. Kết hợp DynamoDB + Redis:\nMô hình Cache-Aside. Cache hit/miss \u0026amp; hiệu năng. Ứng dụng thực tế cho microservices. "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần Phần 1 – Tối ưu chi phí EC2 bằng Lambda Function\nHiểu mô hình tự động Start/Stop EC2 phục vụ mục tiêu tối ưu chi phí. Tạo tag để định danh các EC2 cần tự động bật/tắt. Viết Lambda Function tự động Start/Stop EC2 dựa trên tag. Tích hợp EventBridge Scheduler để chạy Lambda theo lịch. Kiểm tra hoạt động thực tế bằng CloudWatch Logs. Dọn dẹp tài nguyên sau khi thử nghiệm. Phần 2 – Tối ưu chi phí EC2 bằng Savings Plan\nHiểu Savings Plan là gì và nguyên lý giảm chi phí. Phân biệt Compute Saving Plans và EC2 Instance Saving Plans. Hiểu commit USD/hour và cách estimator tính toán. Biết quy trình mua Savings Plan đúng chuẩn AWS. Tính toán chi phí với AWS Pricing Calculator. Các công việc triển khai trong tuần Thứ Công việc chi tiết Bắt đầu Hoàn thành Nguồn 2 Giới thiệu \u0026amp; phân tích mô hình tối ưu chi phí EC2\n• Hiểu sự lãng phí khi EC2 chạy 24/7 nhưng chỉ dùng vài giờ/ngày.\n• Phân tích mô hình: User → EventBridge → Lambda → EC2 API.\n• Phân loại workload phù hợp với Auto Start/Stop.\n• Tìm hiểu hạn chế và rủi ro khi tắt/bật EC2. 03/11 03/11 cloudjourney.awsstudygroup.com 3 Tạo Tag định danh máy chủ cần tự động hóa\n• Tạo Tag Key: Schedule.\n• Tạo Tag Value: office-hours, training-only, weekend-shutdown.\n• Áp dụng tag vào EC2 cần tự động tối ưu chi phí.\n• Kiểm tra bằng AWS CLI: describe-instances --filters tag:Schedule=office-hours. 04/11 04/11 cloudjourney.awsstudygroup.com 4 Tạo IAM Role cho Lambda Function\n• Tạo role tên: LambdaEC2ScheduleRole.\n• Gắn policy: AmazonEC2FullAccess (lab training).\n• Gắn thêm quyền ghi log: AWSLambdaBasicExecutionRole.\n• Kiểm tra trust relationship: lambda.amazonaws.com. 05/11 05/11 cloudjourney.awsstudygroup.com 5 Tạo Lambda Function Start/Stop EC2\n• Viết code Python dùng boto3: StartInstances \u0026amp; StopInstances.\n• Logic lọc EC2 theo tag \u0026lt;Schedule\u0026gt;.\n• Log lại instance ID đã start/stop để kiểm tra.\n• Test thủ công bằng “Test event”. 06/11 06/11 cloudjourney.awsstudygroup.com 6 Tạo EventBridge Scheduler để tự động hóa\n• Tạo rule bật EC2 lúc 8:00 AM.\n• Tạo rule tắt EC2 lúc 18:00 PM.\n• Gán target là Lambda Function.\n• Kiểm tra log thực tế tại CloudWatch Logs. 07/11 07/11 cloudjourney.awsstudygroup.com 7 Kiểm tra kết quả \u0026amp; Dọn dẹp tài nguyên\n• Kiểm thử EC2 bật/tắt chính xác theo lịch.\n• Xem CloudWatch Logs để debug lỗi permission.\n• Xóa EventBridge Rules, Lambda Function, IAM Role sau khi hoàn thành.\n• Review lại chi phí EC2 trước và sau tối ưu. 08/11 08/11 cloudjourney.awsstudygroup.com Kết quả đạt được trong tuần 9: 1. Tối ưu chi phí EC2 với Lambda\nTriển khai thành công mô hình tự động bật/tắt EC2 theo giờ làm việc. Hiểu và sử dụng thành thạo Tag để phân nhóm EC2 cần tối ưu. Viết Lambda Function tự động Start/Stop EC2 bằng boto3. Tự động hóa bằng EventBridge Scheduler theo lịch cố định. Ghi log chi tiết: instance đã start/stop, thời gian chạy, lỗi permission. Giảm được 50–70% chi phí EC2 cho workload chỉ chạy vài giờ mỗi ngày. 2. Tối ưu chi phí với Savings Plan\nHiểu rõ Savings Plan hoạt động dựa trên commit USD/hour.\nTính toán số tiền commit phù hợp bằng AWS Pricing Calculator.\nPhân biệt hai loại Savings Plan:\nCompute Savings Plan → linh hoạt nhất. EC2 Instance Savings Plan → giảm giá sâu nhất. Nắm quy trình mua và áp dụng Savings Plan.\nHiểu lợi ích khi áp dụng đúng: tiết kiệm đến 66% chi phí.\nTóm tắt kiến thức đạt được AWS Lambda + EC2 Automation\nTự động hóa bật/tắt EC2 bằng Lambda. Sử dụng Boto3 để gọi API điều khiển EC2. EventBridge Scheduler dùng để tạo lịch chạy định kỳ. CloudWatch Logs dùng để phân tích \u0026amp; debug. AWS Savings Plans\nCách commit chi phí để giảm giá hạ tầng. Tối ưu hóa cho workload chạy 24/7. Phân biệt Compute vs EC2 Plans. Kết hợp Auto Scheduling + Savings Plan để tối ưu toàn diện. "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "FoodMind Recommender Platform For Prompt-IPoG Giải pháp AWS Serverless hợp nhất cho việc theo dõi và gợi ý bữa ăn cá nhân hóa. 1. Tóm tắt điều hành FoodMind Recommender Platform là nền tảng web thông minh được thiết kế để trở thành một trợ lí ăn uống cá nhân thông minh. Nền tảng tự động tính toán calo mục tiêu (TDEE) dựa trên hồ sơ người dùng, sử dụng AWS Bedrock (AI Tạo sinh) để cho phép người dùng ghi log bữa ăn bằng ngôn ngữ tự nhiên (ví dụ: \u0026ldquo;tôi vừa ăn 1 bát phở bò\u0026rdquo;). Hệ thống cung cấp một tính năng gợi ý bữa ăn (Sáng/Trưa/Tối) thông minh, tự động \u0026ldquo;lọc\u0026rdquo; các món ăn dựa trên mục tiêu calo và các ràng buộc sức khỏe (ví dụ: \u0026ldquo;dị ứng\u0026rdquo;, \u0026ldquo;bệnh gout\u0026rdquo;) của người dùng.\nToàn bộ giải pháp được xây dựng trên kiến trúc serverless với giao diện sử dụng AWS Amplify (Frontend), API Gateway, AWS Lambda, và Amazon DynamoDB (Backend). Cho phép người dùng có thể nhận được gợi ý các món ăn trong ngày dựa trên lượng calo được tính toán theo người dùng sử dụng cần tiêu thụ trong ngày. Dữ liệu được lưu trữ và truy vấn qua Amazon DynamoDB, đảm bảo hiệu năng cao và mở rộng linh hoạt.\nGiải pháp tập trung vào sự kết hợp giữa AI và dữ liệu thực tế để hỗ trợ ra quyết định tìm món ăn linh hoạt và thiết kế dashboard để có thể xem quá trình theo dõi bữa ăn hàng ngày hiệu quả.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nNhiều người dùng gặp khó khăn trong việc quản lý chế độ ăn uống hàng ngày — không biết nên ăn bao nhiêu calo, món nào phù hợp với mục tiêu cá nhân cho mỗi ngày. Việc ghi chép thủ công và tra cứu dinh dưỡng gây mất thời gian, thiếu chính xác và không có tính cá nhân hóa.\nGiải pháp\nFoodMind Recommender Platform ứng dụng AI và AWS Cloud để tự động hóa toàn bộ quy trình theo dõi và gợi ý bữa ăn:\nTự động hóa Mục tiêu: Hệ thống tự động tính toán Calo Mục tiêu cho người dùng (dựa trên công thức Mifflin-St Jeor) ngay khi họ cập nhật hồ sơ. Tự động hóa Gợi ý: Hệ thống cung cấp API GET /recommendations sử dụng \u0026ldquo;logic nghiệp vụ\u0026rdquo; (do Lambda thực thi) để \u0026ldquo;lọc\u0026rdquo; (filter) kho dữ liệu món ăn, dựa trên Calo Mục tiêu (ví dụ: bữa trưa \u0026lt; 700 calo) và Luật cấm Bệnh lý (ví dụ: không chứa \u0026ldquo;thịt đỏ\u0026rdquo; cho bệnh gout). Tự động hóa Ghi log (AI Logging): Hệ thống cung cấp API POST /log-food sử dụng AWS Bedrock để \u0026ldquo;bóc tách\u0026rdquo; (parse) ngôn ngữ tự nhiên của người dùng. Hệ thống tự tra cứu calo và lưu vào nhật ký. Tự động hóa Học hỏi: Khi người dùng log một món ăn mới (ví dụ: \u0026ldquo;bún đậu mắm tôm\u0026rdquo;) mà hệ thống không biết, AWS Bedrock sẽ được dùng để \u0026ldquo;ước tính\u0026rdquo; calo và \u0026ldquo;tự động lưu\u0026rdquo; món mới này vào kho tri thức. Theo dõi Trực quan: Cung cấp dashboard (trên Amplify) hiển thị lịch sử ăn uống 7 ngày qua, giúp người dùng quan sát và theo dõi chế độ ăn uống cá nhân. Người dùng chỉ cần nhập thông tin, hệ thống sẽ tự động hiểu, phân tích và đề xuất–gợi ý bữa ăn phù hợp với sức khỏe và mục tiêu cá nhân.\nLợi ích và hoàn vốn đầu tư (ROI)\nTiết kiệm thời gian theo dõi dinh dưỡng, loại bỏ thao tác thủ công. Mang đến trải nghiệm AI thực tế, có tính cá nhân hóa cao. Tạo cơ sở dữ liệu chuẩn hóa cho nghiên cứu về AI trong lĩnh vực ẩm thực và cá nhân hóa bữa ăn. Chi phí thấp nhờ kiến trúc serverless. Dễ mở rộng và tái sử dụng mô hình cho các ứng dụng chăm sóc sức khỏe khác. ROI ước tính: hoàn vốn trong 6 tháng thông qua tiết kiệm thời gian phát triển và tái sử dụng mô hình AI đã có sẵn. Chi phí ước tính: khoảng 10–15 USD/tháng. 3. Kiến trúc giải pháp Nền tảng được xây dựng hoàn toàn trên mô hình AI-as-a-Service kết hợp AWS Serverless, đảm bảo hiệu năng cao, bảo mật và khả năng mở rộng linh hoạt. Dữ liệu dĩnh dưỡng về lượng calo của các món ăn được thu thập lưu trữ trong Amazon DynamoDB, sau đó sẽ gợi ý bữa ăn dựa phù hợp với lượng tính toán Calo mục tiêu. Amazon Bedrock được sử dụng để phân tích xử lý ngôn ngữ tự nhiên của người dùng tra cứu Calo món ăn và lưu vào Amazon DynamoDB. AWS Amplify lưu trữ giao diện web Next.js và Amazon Cognito đảm bảo xác thực người dùng an toàn. Kiến trúc được trình bày chi tiết bên dưới:\nDịch vụ AWS sử dụng\nAWS Amplify: Triển khai và lưu trữ giao diện web của nền tảng (Next.js), kết nối CI/CD trực tiếp với GitLab để tự động build và deploy. Amazon Route 53 + AWS WAF + Amazon CloudFront: Tầng Edge bảo vệ và phân phối nội dung nhanh chóng, đảm bảo bảo mật và hiệu năng truy cập toàn cầu. Amazon Cognito: Quản lý xác thực người dùng, đăng nhập và phân quyền truy cập an toàn cho từng tài khoản. Amazon API Gateway: Cung cấp endpoint cho các tác vụ như GET /Recommendation, POST /Log, GET /Dashboard, kết nối trực tiếp với Lambda. AWS Lambda (Private Subnet): Xử lý logic ứng dụng, gọi Bedrock và DynamoDB thông qua các VPC Endpoint để đảm bảo bảo mật và hiệu năng. AWS Bedrock: Sinh mô tả món ăn, chuẩn hóa log bữa ăn bằng ngôn ngữ tự nhiên và lưu vào DynamoDB phục vụ gợi ý bữa ăn cá nhân hóa. Amazon DynamoDB: Lưu trữ dữ liệu người dùng, nhật ký ăn uống, mục tiêu calo, và dữ liệu gợi ý – đảm bảo khả năng mở rộng linh hoạt. AWS Secrets Manager: Bảo mật thông tin xác thực (API Key, Bedrock credentials) cho Lambda và dịch vụ backend. Amazon CloudWatch \u0026amp; AWS CloudTrail: Theo dõi log, truy cập và hiệu năng toàn hệ thống; hỗ trợ giám sát và khôi phục sự cố. Amazon S3: Lưu trữ log. AWS IAM: Quản lý phân quyền truy cập chi tiết giữa các dịch vụ và người dùng. Amazon VPC: Cách ly Lambda trong subnet riêng, đảm bảo kết nối an toàn nội bộ giữa Lambda – DynamoDB – Bedrock.\nThiết kế thành phần\nQuản lý người dùng: Amazon Cognito quản lý quyền truy cập của người dùng. Phân phối \u0026amp; Bảo vệ truy cập: Route 53 định tuyến tên miền, AWS WAF bảo vệ khỏi tấn công web (SQL Injection, DDoS) và CloudFront tăng tốc độ tải nội dung và phân phối toàn cầu. Giao diện web: Amplify lưu trữ ứng dụng Next.js. Ghi nhật ký \u0026amp; gợi ý bữa ăn: Người dùng nhập dữ liệu (text) lưu vào DynamoDB, Lambda gợi ý món ăn theo số tính toán Calo. Phân tích bữa ăn: Lambda gọi Bedrock xử lý thông tin bữa ăn bằng ngôn ngữ tự nhiên của user nhập vào, bóc tách và tìm nhật ký Calo của món và lưu lại DynamoDB nếu món mới. Hiển thị dashboard: Amplify hiển thị biểu đồ calo theo ngày/tuần/tháng sau khi user cập nhật bữa ăn. Xác thực \u0026amp; bảo mật: Cognito đảm bảo đăng nhập an toàn và quản lý user. Giám sát \u0026amp; theo dõi: Amazon CloudWatch theo dõi log, hiệu năng Lambda, AWS CloudTrail lưu lại lịch sử thao tác và truy cập dịch vụ. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nNghiên cứu và Thiết kế: Thiết kế pipeline AI + Cloud, kiểm tra tính khả thi và vẽ sơ đồ hệ thống AWS (5 Tuần đầu tiên). Tính toán chi phí và tối ưu giải pháp: Kiểm tra lại chi phí các dịch vụ trong kiến trúc để tối ưu chi phí (Tuần 6). Phát triển, Kiểm thử và triển khai: Lưu dữ liệu ban đầu, sau đó tạo giao diện wed với Next.js, kiểm thử các luồng tính năng API, tốc độ và vận hành sản phẩm (Tuần 7 - tuần 11). Yêu cầu kỹ thuật\nDữ liệu Calo món ăn: Thu thập dữ liệu ban đầu và dùng script AWS SDK (Boto3) để nạp vào DynamoDB. Nền tảng gợi ý quán ăn: Kiến thức thực tế về AWS Amplify (lưu trữ Next.js), S3 (bucket), Cognito. Kiến thức thực tế về AWS Serverless (Lambda, DynamoDB, API Gateway), thiết kế schema DynamoDB (PK, SK), và cách dùng Bedrock API. 5. Lộ trình \u0026amp; Mốc triển khai Thực tập (Tháng 1–3): Tháng 1: Học và làm chủ các dịch vụ AWS. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Theo dõi, cải tiến hệ thống gợi ý và mở rộng dữ liệu trong vòng 1 năm. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator. Hoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nAWS Amplify: 0.50 USD/tháng (~100 MB, traffic thấp).\nAWS Lambda: 0.20-0.30 USD/tháng ( 100.000 request/tháng, thời gian chạy trung bình \u0026lt;1s ).\nAmazon API Gateway: 0.10-o.20 USD/tháng ( 50.000 request REST API/tháng).\nAmazon DynamoDB: 0.10-0.30 USD/tháng ( 50 MB dữ liệu, ~20.000 request/tháng).\nAmazon S3 (lưu trữ log/back-up): 0.10 USD/tháng (\u0026lt;2GB).\nAWS Bedrock: 3,00-500 USD/tháng ( vài nghìn token/tháng).\nCloudWatch + CloudTrail + IAM etc: ~ 0.10-USD.\nAmazon Cognito: 0.00 USD/tháng ( \u0026lt;50 người dùng hoạt động (Free Tier)).\nTổng: ~4-6 USD/tháng, ~50-75 USD/12 tháng.\n7. Đánh giá rủi ro Ma trận rủi ro\nLỗi AI xử lý sai: Ảnh hưởng cao, xác suất thấp. Quá tải request: Ảnh hưởng trung bình, xác suất Thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Lỗi logic: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nSai lệch AI: Dùng \u0026ldquo;prompt engineering\u0026rdquo; kỹ lưỡng. Quá tải request API: Giới hạn truy cập qua API Gateway. Chi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Logic: Điều chình code kĩ lưỡng với các hàm lambda. Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Trải nghiệm người dùng nâng cao: Cung cấp một trợ lý bữa ăn \u0026ldquo;thông minh\u0026rdquo;, xóa bỏ mọi rào cản thủ công trong việc ghi log và chọn món.\nTích hợp AI thực tế: Ứng dụng Bedrock trong hệ thống sản phẩm hoàn chỉnh.\nTạo nền tảng dữ liệu dinh dưỡng: Có thể mở rộng, phục vụ nghiên cứu AI \u0026amp; y tế.\nKhả năng mở rộng: tích hợp thêm phân tích hình ảnh món ăn, chat AI coach, và ứng dụng di động.\n"
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "1. Tạo IAM Role bằng Console có quyền cần thiết Tạo một IAM role tên bedrock và gán các quyền cần thiết để sử dụng Amazon Bedrock: quyền gọi mô hình/agent (bedrock:InvokeModel, bedrock:CreateAgent, bedrock:InvokeAgent), quyền truy cập S3 (đọc/ghi) để nạp tài liệu cho Knowledge Base, và quyền CloudWatch Logs để ghi nhật ký v.v.v.\nMẫu tài liệu để nạp vào knowledge base (PDF, văn bản, markdown, HTML) Chúng ta sẽ tạo 1 tài liệu giới thiệu Amazon Web Services (Text) Amazon Web Services (AWS) là nền tảng điện toán đám mây của Amazon, chính thức ra mắt vào năm 2006. Ban đầu, AWS được tạo ra nhằm giải quyết vấn đề nội bộ của Amazon: họ cần một hạ tầng có khả năng mở rộng linh hoạt để phục vụ hệ thống thương mại điện tử khổng lồ của mình. Khi nhận ra rằng các doanh nghiệp khác cũng gặp những khó khăn tương tự về hạ tầng CNTT, Amazon quyết định thương mại hóa nền tảng này và cung cấp nó như một dịch vụ đám mây. AWS ra đời với mục tiêu giúp tổ chức và doanh nghiệp giảm chi phí đầu tư máy chủ, triển khai ứng dụng nhanh hơn, và tận dụng hạ tầng theo nhu cầu thay vì phải tự vận hành trung tâm dữ liệu. Đây là tầm nhìn cốt lõi đằng sau mô hình “điện toán đám mây” hiện đại: đưa tài nguyên tính toán trở thành một loại dịch vụ tiện ích có thể dùng ngay, giống như điện và nước. Trong những năm tiếp theo, AWS phát triển thần tốc, từ vài dịch vụ cơ bản như lưu trữ (Amazon S3) và máy ảo (EC2) thành hệ sinh thái hơn 200 dịch vụ bao gồm máy chủ ảo, container, trí tuệ nhân tạo, lưu trữ dữ liệu, bảo mật, IoT và phân tích dữ liệu. Nhờ khả năng mở rộng toàn cầu với hàng chục Region và hàng trăm điểm Edge trên thế giới, AWS trở thành nền tảng cloud dẫn đầu thị trường. Mục tiêu dài hạn của AWS là mang đến một môi trường điện toán an toàn, linh hoạt và có thể đáp ứng mọi nhu cầu của người dùng — từ startup nhỏ cho đến các tập đoàn lớn. AWS hướng đến việc giúp doanh nghiệp tập trung vào phát triển sản phẩm, thay vì tốn thời gian vận hành hạ tầng. Đến nay, AWS được sử dụng bởi các công ty công nghệ hàng đầu, chính phủ, trường đại học và hàng triệu tổ chức trên toàn thế giới. AWS không chỉ là dịch vụ hạ tầng, mà còn trở thành nền tảng quan trọng thúc đẩy đổi mới trong các lĩnh vực như học máy, Big Data, AI generative với (Amazon Bedrock), và phát triển ứng dụng serverless. Nhờ đó, AWS đóng vai trò quan trọng trong việc hình thành thế hệ công nghệ hiện đại. "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/5-workshop/5.4-s3-onprem/5.4.2-create-agent/",
	"title": "Tạo Agent",
	"tags": [],
	"description": "",
	"content": " Ở trang giao diện của Aws Bedrock mình chọn phía trái Agent Bạn hãy điền tên và kiến trúc cho Agent để cho nó hiểu ngữ cảnh Ví dụ tôi viết nó là nhân viên tư vấn của Aws . Nhưng trước khi có được câu trả lời như thế thì tôi phải nạp Knowledge base cho nó hiểu - Nội dung của Knowledge base Lưu ý bạn nên cấu hình theo nhu cầu và nên cấp quyền cần thiết cho nó\n"
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần: Phần 1 – Xây dựng backend Document Management System (DMS) với Lambda + DynamoDB\nHiểu kiến trúc tổng thể của hệ thống Document Management System. Thiết kế bảng DynamoDB theo đúng access patterns thực tế của ứng dụng. Tạo các Lambda Functions phục vụ CRUD tài liệu (Create, Read, Query, Delete). Thiết lập IAM Role tối ưu cho Lambda theo nguyên tắc least privilege. Kiểm thử API bằng test event và CloudWatch Logs. Chuẩn bị nền tảng cho việc tích hợp API Gateway và Amplify ở tuần kế tiếp. Phần 2 – Hiểu rõ cách ứng dụng DMS sẽ mở rộng trong các tuần tiếp theo\nNắm rõ cách tích hợp Cognito Authentication, Amplify Storage. Xác định vai trò của DynamoDB Streams trong search engine với OpenSearch. Hiểu quá trình triển khai toàn bộ backend bằng AWS SAM. Hiểu luồng CI/CD dự kiến sử dụng AWS CodePipeline. Các công việc triển khai trong tuần Thứ Công việc chi tiết Bắt đầu Hoàn thành Nguồn 2 Phân tích kiến trúc tổng quan của hệ thống DMS\n• Hiểu mục tiêu ứng dụng: upload, xem, tải xuống, xoá và tìm kiếm tài liệu.\n• Xác định các thành phần chính: Lambda, DynamoDB, S3, Cognito, API Gateway.\n• Phân tích workflow: Upload → Lưu metadata → Xử lý tìm kiếm.\n• Liệt kê API endpoints cần thiết cho backend. 10/11 10/11 cloudjourney.awsstudygroup.com 3 Thiết kế DynamoDB Table cho Document Metadata\n• Tạo bảng Documents với PK = userId, SK = documentId.\n• Thiết kế attributes: filename, fileType, size, tags, createdAt, updatedAt.\n• Phân tích access patterns: Query theo user, Get theo documentId, lọc theo tag.\n• Chuẩn bị dữ liệu mẫu và test với AWS Console + CLI. 11/11 11/11 cloudjourney.awsstudygroup.com 4 Tạo IAM Role cho Lambda Functions\n• Tạo Role DMSLambdaRole.\n• Gán quyền DynamoDB CRUD: GetItem, Query, PutItem, DeleteItem.\n• Gán quyền CloudWatch Logs để ghi log.\n• Kiểm tra Trust Policy: lambda.amazonaws.com.\n• Kiểm thử việc assume role bằng Lambda test environment. 12/11 12/11 cloudjourney.awsstudygroup.com 5 Viết Lambda Function CreateDocument\n• Validate input từ người dùng.\n• Tự tạo documentId theo UUID.\n• Lưu metadata vào DynamoDB bằng put_item.\n• Ghi log input/output để phục vụ giám sát.\n• Test bằng test event trên AWS Lambda + CloudWatch Logs.\n• Tối ưu exception handling: missing fields, DynamoDB errors. 13/11 13/11 cloudjourney.awsstudygroup.com 6 Viết Lambda Function GetDocuments \u0026amp; GetDocumentById\n• Viết query để lấy tất cả tài liệu theo userId.\n• Hỗ trợ phân trang bằng LastEvaluatedKey.\n• Viết GetDocumentById để lấy chi tiết theo documentId.\n• Trả về JSON chuẩn phục vụ front-end.\n• Kiểm thử với dữ liệu mẫu trên DynamoDB. 14/11 14/11 cloudjourney.awsstudygroup.com 7 Viết Lambda Function DeleteDocument \u0026amp; Cleanup\n• Kiểm tra sự tồn tại của tài liệu trước khi xoá.\n• Xoá metadata bằng delete_item.\n• Chuẩn bị logic xoá file thật trên S3 (tuần tiếp theo).\n• Ghi log chi tiết quá trình xoá để theo dõi.\n• Dọn dẹp tài nguyên test, xoá các records không cần thiết. 15/11 15/11 cloudjourney.awsstudygroup.com Kết quả đạt được trong tuần 10 : 1. Hoàn thiện bảng DynamoDB với thiết kế tối ưu\nXây dựng đầy đủ bảng Documents đáp ứng đầy đủ nhu cầu của một Document Management System. Thiết kế PK/SK để tối ưu cho Query theo user \u0026amp; lấy dữ liệu chi tiết. Chuẩn bị mô hình dữ liệu có thể mở rộng khi tích hợp OpenSearch hoặc DynamoDB Streams. 2. Viết thành công bộ Lambda Functions phục vụ CRUD cho hệ thống\nTạo mới tài liệu với CreateDocument. Truy vấn danh sách tài liệu theo userId với GetDocuments. Lấy chi tiết theo documentId với GetDocumentById. Xoá tài liệu với DeleteDocument. Tất cả function đều tuân thủ chuẩn Serverless, logging đầy đủ, retry-safe. 3. Áp dụng đầy đủ best practices về bảo mật và logging\nIAM Role tuân thủ nguyên tắc least privilege. CloudWatch Logs dùng để trace toàn bộ luồng xử lý. Xử lý lỗi rõ ràng: input error, DynamoDB error, missing item. 4. Hiểu rõ kiến trúc tổng thể của DMS và sẵn sàng cho tuần tiếp theo\nNắm workflow Authentication – API – Storage – Metadata. Hiểu cách Lambda sẽ kết nối với API Gateway trong tuần 11. Tạo nền tảng kỹ thuật để tuần sau triển khai Amplify Storage + Authentication. Tóm tắt kiến thức đạt được AWS DynamoDB\nThiết kế bảng theo access patterns. Sử dụng Partition/Sort key đúng mục đích. Query, PutItem, GetItem, DeleteItem trong Boto3. AWS Lambda\nViết code serverless cho CRUD. Tạo IAM Role + policy tối ưu. Logging bằng CloudWatch Logs. Error handling chuẩn sản phẩm. DMS Architecture\nMetadata lưu DynamoDB. File thật lưu ở S3. Authentication bằng Cognito. API được điều phối bằng Lambda + API Gateway. "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần Phần 1 – Serverless: Sử dụng Amplify Authentication và Storage\nHiểu cách hoạt động của Amplify Libraries, Amplify Auth và Amplify Storage. Tích hợp Cognito Authentication vào ứng dụng web. Tạo hệ thống upload file từ frontend và lưu trữ vào S3 bằng Amplify Storage. Tìm hiểu các cấp độ truy cập (public / protected / private). Nắm được tổng quan kiến trúc sử dụng Cognito + S3 + Amplify. Phần 2 – Serverless: Xây dựng Front-end gọi API Gateway\nHiểu quy trình tạo API Gateway kết nối Lambda. Tạo frontend sử dụng JavaScript/React gọi API Gateway → Lambda → DynamoDB. Kiểm thử API từ Postman và kiểm thử trực tiếp từ frontend. Nắm rõ kiến trúc front-end → API Gateway → Lambda → DynamoDB. Các công việc triển khai trong tuần Thứ Công việc chi tiết Bắt đầu Hoàn thành Nguồn 2 Giới thiệu Amplify \u0026amp; Chuẩn bị môi trường\n• Tìm hiểu Amplify Libraries, CLI và UI Components.\n• Khởi tạo project web để tích hợp Amplify.\n• Cài đặt gói @aws-amplify/ui và aws-amplify.\n• Cấu hình môi trường AWS. 17/11 17/11 cloudjourney.awsstudygroup.com 3 Xác thực với Amplify Auth (Cognito)\n• Tạo User Pool \u0026amp; Identity Pool.\n• Cấu hình Amplify Auth trong frontend.\n• Tạo UI login bằng Amplify UI Components.\n• Test đăng ký, đăng nhập, reset password. 18/11 18/11 cloudjourney.awsstudygroup.com 4 Lưu trữ file với Amplify Storage (S3)\n• Tạo S3 bucket qua Amplify.\n• Cấu hình quyền truy cập public/protected/private.\n• Viết logic upload file từ front-end → S3.\n• Kiểm tra file trên S3 console.\n• Viết hàm list files \u0026amp; get URL. 19/11 19/11 cloudjourney.awsstudygroup.com 5 Triển khai API Gateway kết nối Lambda\n• Tạo API Gateway REST.\n• Map method → Lambda CRUD functions.\n• Enable CORS cho front-end.\n• Triển khai ARN mới cho Lambda. 20/11 20/11 cloudjourney.awsstudygroup.com 6 Test API với Postman\n• Gửi request GET/POST/DELETE.\n• Kèm Authorization token từ Cognito.\n• Kiểm tra log CloudWatch.\n• Fix lỗi CORS và IAM permission. 21/11 21/11 cloudjourney.awsstudygroup.com 7 Tích hợp Front-end gọi API Gateway\n• Viết service JavaScript gọi API Gateway.\n• Gắn token Cognito vào request header.\n• Render kết quả trả về từ Lambda/DynamoDB.\n• Test end-to-end: Front-end → API → Lambda → DynamoDB.\n• Dọn dẹp tài nguyên test. 22/11 22/11 cloudjourney.awsstudygroup.com Kết quả đạt được trong tuần 11 : 1. Hoàn thiện Authentication với Amplify + Cognito\nĐăng nhập/đăng ký người dùng hoạt động hoàn chỉnh. Xử lý các luồng xác thực: login, sign-up, confirm code, reset password. Front-end có thể truy cập JWT token để gửi request đến API Gateway. Hiểu sâu về cơ chế User Pool \u0026amp; Identity Pool. 2. Upload \u0026amp; quản lý file bằng Amplify Storage + S3\nUpload file từ frontend thành công. S3 bucket được tạo tự động bởi Amplify. Thử nghiệm thành công 3 cấp độ truy cập:\npublic, protected, private. Implement được các hàm: upload list files get URL delete file (tùy chọn) 3. Xây dựng API Gateway hoàn chỉnh cho DMS\nTạo REST API bao gồm các route CRUD tài liệu. Gắn Lambda functions từ tuần trước. Kích hoạt CORS đầy đủ. Test tất cả API bằng Postman với JWT Cognito. 4. Tích hợp Front-end gọi API Gateway\nViết đầy đủ logic frontend gửi request kèm token Cognito.\nParse và hiển thị danh sách tài liệu từ DynamoDB.\nThực hiện thành công luồng:\nLogin → Upload file → Lưu metadata → Query → Hiển thị kết quả\nTóm tắt kiến thức đạt được Amplify\nAmplify Auth sử dụng Cognito làm backend. Amplify Storage hỗ trợ tương tác S3 đơn giản. Amplify UI giúp tạo screen login nhanh chóng. Cognito(Authentication)\nUser Pool quản lý người dùng. Identity Pool cấp quyền tạm thời để truy cập S3. JWT token được dùng để gọi API Gateway. S3(Storage)\nTổ chức object theo cấp độ: public / private / protected. Upload trực tiếp từ frontend thông qua Amplify. API Gateway\nĐịnh tuyến request vào Lambda. CORS configuration rất quan trọng với frontend. Có thể yêu cầu token Cognito để xác thực. Lambda + DynamoDB\nLambda xử lý logic CRUD. DynamoDB lưu metadata tài liệu. API Gateway giúp frontend truy vấn dữ liệu thông qua Lambda. "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu trong tuần Phần 1 – Giới thiệu Amazon Bedrock \u0026amp; Foundation Models\nHiểu kiến trúc Amazon Bedrock và các dịch vụ chính. Học cách truy cập và sử dụng foundation models (FM) qua Bedrock. Tìm hiểu các mô hình: Claude, Llama, Mistral, Amazon Titan… Phân biệt mô hình sinh văn bản, embeddings và mô hình đa phương thức. Phần 2 – Xây dựng AI Agent với Bedrock Agent\nHiểu AI Agent là gì và cách hoạt động.\nHọc các khái niệm:\nAction groups Knowledge bases Orchestration Tích hợp Lambda functions Cấu hình một AI Agent có khả năng gọi công cụ qua Lambda.\nPhần 3 – Sử dụng Knowledge Base cho Enterprise Search\nTạo Knowledge Base với vector embeddings. Kết nối Bedrock KB với tài liệu trong S3. Kiểm thử semantic search và RAG (Retrieval Augmented Generation). Tích hợp KB vào Bedrock Agent. Phần 4 – Tích hợp Front-end với Bedrock Agent\nXây dựng giao diện chat web để giao tiếp với Bedrock Agent. Thực hiện streaming response. Luồng hoạt động: Input người dùng → Agent → (KB, Lambda Tools) → Trả về đáp án. Triển khai front-end bằng Amplify Hosting. Các công việc triển khai trong tuần Thứ Công việc chi tiết Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu Hai Học nền tảng Amazon Bedrock\n• Khám phá danh mục mô hình.\n• Test Claude / Llama 3 trong Playground.\n• So sánh giá \u0026amp; khả năng.\n• Tìm hiểu API Bedrock cơ bản. 24/11 24/11 cloudjourney.awsstudygroup.com Ba Xây dựng ứng dụng Text Generation đầu tiên với Bedrock\n• Viết Lambda gọi Bedrock InvokeModel API.\n• Test tham số temperature, max tokens.\n• Xây dựng CLI nhỏ bằng SDK. 25/11 25/11 cloudjourney.awsstudygroup.com Tư Tạo Bedrock Agent\n• Thiết lập cấu hình agent.\n• Thêm instructions \u0026amp; guardrails.\n• Tạo Action Group sử dụng Lambda.\n• Kết nối agent với bảng DynamoDB thử nghiệm. 26/11 26/11 cloudjourney.awsstudygroup.com Năm Xây dựng Knowledge Base (RAG System)\n• Tạo S3 bucket chứa tài liệu.\n• Cấu hình embeddings (Titan Embeddings G1).\n• Test hỏi đáp với PDF/CSV.\n• Tích hợp KB vào Agent. 27/11 27/11 cloudjourney.awsstudygroup.com Sáu Kiểm thử AI Agent End-to-End\n• Chat: Agent → KB → Lambda → Trả lời.\n• Fix lỗi IAM, KMS.\n• Kiểm thử hội thoại nhiều lượt.\n• Thêm fallback \u0026amp; error handling. 28/11 28/11 cloudjourney.awsstudygroup.com Bảy Xây dựng ứng dụng Chat Frontend bằng Amplify\n• Xây UI React Chat.\n• Kết nối UI với Bedrock Agent qua API Gateway.\n• Thực hiện streaming output.\n• Deploy bằng Amplify Hosting. 29/11 29/11 cloudjourney.awsstudygroup.com Kết quả đạt được trong tuần 12 : 1. Nắm vững Amazon Bedrock \u0026amp; Foundation Models\nBiết cách gọi mô hình thông qua SDK. Thử nghiệm nhiều nhóm mô hình khác nhau. Hiểu các use-case: sinh văn bản, tóm tắt, sinh mã, embeddings. 2. Xây dựng thành công một AI Agent hoàn chỉnh\nAgent hiểu intent người dùng. Dùng Action Groups để chạy Lambda. Hỗ trợ reasoning nhiều bước. Có thể truy vấn DynamoDB qua Lambda. 3. Tạo Knowledge Base tích hợp RAG\nTạo vector store từ tài liệu trong S3. Chạy thành công semantic search. Agent trả lời chính xác hơn nhờ tích hợp KB. 4. Xây dựng giao diện chat kết nối Bedrock\nTạo UI chat bằng React. Tích hợp API Gateway để giao tiếp an toàn. Thực hiện thành công streaming response. Luồng hoàn chỉnh: UI → Agent → KB/Lambda → Trả lời. Tóm tắt kiến thức đã học Amazon Bedrock\nCung cấp quyền truy cập các mô hình mạnh nhất hiện nay. Fully managed, bảo mật cấp doanh nghiệp. Hỗ trợ sinh văn bản, embeddings và đa phương thức. Bedrock Agents\nAgent có khả năng duy trì hội thoại và gọi công cụ. Action Groups cho phép tích hợp backend thực. Guardrails đảm bảo an toàn nội dung. Knowledge Bases\nEmbeddings tạo semantic search chính xác hơn. KB + Agent = hệ thống RAG hoàn chỉnh. Tự đồng bộ với tài liệu trong S3. Tích hợp \u0026amp; Triển khai\nLambda để xử lý logic backend. API Gateway để kết nối từ frontend. Amplify để deploy UI. "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Hiện đại hóa ứng dụng Java với Amazon Q Developer và Visual Studio Code Blog này trình bày quy trình hiện đại hóa các ứng dụng Java cũ bằng Amazon Q Developer và Visual Studio Code. Nội dung bao gồm cấu hình môi trường phát triển với nhiều phiên bản JDK, tích hợp Amazon Q Developer và sử dụng tính năng /transform để tự động chuyển đổi ứng dụng từ Java 8 hoặc Java 11 lên Java 21. Bài viết cũng mô tả khả năng tạo kiểm thử đơn vị tự động bằng /test, giúp giảm nợ kỹ thuật, tối ưu hiệu suất và đơn giản hóa việc bảo trì ứng dụng Java.\nHiện đại hóa khối lượng công việc giao dịch với giá đỡ AWS Outposts thế hệ tiếp theo Blog này giới thiệu cách hiện đại hóa hệ thống giao dịch tài chính bằng AWS Outposts thế hệ mới, sử dụng các phiên bản Amazon EC2 có kết nối mạng tăng tốc để đạt độ trễ thấp và hiệu suất xác định. Nội dung trình bày các khả năng chính như bare metal compute, multicast, đồng bộ thời gian PTP và các mô hình triển khai Outposts giúp đảm bảo tuân thủ, ổn định và tích hợp liền mạch với AWS.\nChỉnh sửa Amazon EBS volumes trên Kubernetes với Volume Attribute Class Bài blog này giải thích cách chỉnh sửa ổ đĩa Amazon EBS trong Kubernetes bằng API mới VolumeAttributesClass (VAC). Tính năng này cho phép thay đổi loại ổ đĩa, IOPS, thông lượng và thẻ tài nguyên AWS mà không làm ứng dụng dừng hoạt động. Bài viết cũng hướng dẫn các quy trình phổ biến như nâng cấp từ gp2 → gp3 để tiết kiệm chi phí, tăng hiệu suất khối lượng EBS, và tự động hóa backup bằng Amazon Data Lifecycle Manager. Nội dung đi kèm ví dụ từng bước sử dụng PVC, StorageClass và trình điều khiển Amazon EBS CSI.\n"
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/5-workshop/5.3-vpc-to-internet/",
	"title": "Khám phá Bedrock Console",
	"tags": [],
	"description": "",
	"content": " Trong phần này, bạn sẽ khám phá Amazon Bedrock Console và thực hiện các kiểm thử nhanh trong Playground để đánh giá cả chất lượng và chi phí của các mô hình. Trước khi chọn model cho môi trường production, hãy đo lượng token trung bình, so sánh phản hồi giữa các model, và ước tính chi phí để chọn mô hình phù hợp với ngân sách. Nội dung Khám phá Bedrock "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": "Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: Cloud Day\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: Generative AI with Amazon Bedrock\nThời gian: 08:30 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/5-workshop/5.4-s3-onprem/",
	"title": "Thiết kế Agent",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, chúng ta sẽ tìm hiểu cách thiết kế một AI Agent hoạt động trên nền tảng Amazon Bedrock. Mục tiêu chính của chương là giúp bạn hiểu được Agent là gì, cách nó xử lý yêu cầu của người dùng, và tại sao Agent đóng vai trò quan trọng trong việc xây dựng các ứng dụng AI hiện đại.\nỞ phần tổng quan này, chúng ta sẽ phác thảo các thành phần quan trọng trong quá trình thiết kế một Agent, bao gồm cách xác định nhiệm vụ của Agent, mô tả hành vi mong muốn, cấu trúc workflow, lựa chọn mô hình nền tảng (Foundation Model), cũng như những nguyên tắc cần tuân thủ để Agent hoạt động ổn định và chính xác. Phần này cũng giới thiệu cách Agent tương tác với dữ liệu doanh nghiệp và tích hợp với các dịch vụ AWS nhằm triển khai vào môi trường thực tế.\nNội Dung Tạo Knowledge base Tạo Agent "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/5-workshop/5.5-policy/",
	"title": "Thử nghiệm ở on premise",
	"tags": [],
	"description": "",
	"content": "Trong phần này, chúng ta sẽ thực hiện triển khai và thử nghiệm mô hình AI trong môi trường on-premise (tại chỗ). Đây là bước quan trọng để đánh giá tính khả thi và hiệu suất của hệ thống trong điều kiện thực tế trước khi đưa vào sản xuất 1.\nChúng ta sẽ kết nối qua python (boto3) Đầu tiên ta phải biết vùng của mình , Agent ID , Aliases Id\nPhải có acesskey Id , secret key : Lưu ý không thể để lộ 2 key này , nếu không sẽ bị người ngoài dùng dịch vụ và mình sẽ bị mất tiền\nThử promt xem có trả về kết quả hay không nếu có thì coi như đã thành công . "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "XÂY DỰNG AI AGENT VỚI AWS BEDROCK Tổng quan Amazon Bedrock: Amazon Bedrock là một dịch vụ AI/ML được quản lý hoàn toàn (fully managed) do AWS cung cấp, cho phép doanh nghiệp dễ dàng truy cập và sử dụng các mô hình nền tảng (Foundation Models – FM) hàng đầu như Claude, Llama, Stable Diffusion, Amazon Titan… mà không cần xây dựng hạ tầng AI phức tạp.\nChúng ta có thể gọi các mô hình này thông qua Bedrock API hoặc Bedrock console mà không cần tự triển khai hạ tầng AI.\nAI Agents thực hiện các nhiệm vụ nhiều bước bằng cách điều phối các tương tác giữa các Mô hình nền tảng, Nguồn dữ liệu và các ứng dụng phần mềm doanh nghiệp.\nNội dung Tổng quan về workshop Chuẩn bị môi trường AWS Khám phá Bedrock Console Thiết kế Agent AI cơ bản Kiểm tra và triển khai Dọn dẹp tài nguyên "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong workshop này!\nTrong workshop này, bạn đã học về AI Agent với bedrock trên Aws và thử bằng python (boto3) .\nDọn dẹp Điều hướng đến AWS Bedrock trên phía trái của bảng điều khiển . Chọn Agent . Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Điều hướng đến AWS Bedrock trên phía trái của bảng điều khiển . Chọn vào Knoweledge Base .Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo; Xóa IAM Role không còn dùng "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại Amazon Web Services (AWS) từ 08/12 đến 12/12, em đã có cơ hội quý báu để học hỏi, rèn luyện và áp dụng những kiến thức được trang bị trên giảng đường vào một môi trường làm việc thực tế chuyên nghiệp. Em đã tham gia vào việc **tìm hiểu sâu về dịch vụ Amazon Bedrock và hệ sinh thái AI của AWS, cũng như nhiều dịch vụ của Aws, qua đó cải thiện đáng kể kỹ năng phân tích yêu cầu, tư duy kiến trúc hệ thống và làm việc với tài liệu kỹ thuật.\nVề tác phong, em luôn cố gắng hoàn thành tốt nhiệm vụ được giao, tuân thủ nội quy và văn hóa của AWS, đồng thời tích cực trao đổi, học hỏi từ các anh chị hướng dẫn và các bạn để nâng cao hiệu quả công việc.\nĐể phản ánh một cách trung thực và khách quan nhất về quá trình thực tập của mình, em xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ✅ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ✅ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ✅ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ Điểm cần cải thiện Nâng cao tính kỷ luật: Cần ý thức và tuân thủ nghiêm ngặt hơn nữa các quy định về giờ giấc và quy trình nội bộ của công ty. Phát triển tư duy giải quyết vấn đề: Cần rèn luyện để tiếp cận vấn đề một cách có hệ thống và logic hơn, từ phân tích nguyên nhân đến đề xuất các giải pháp khả thi. Cải thiện kỹ năng giao tiếp: Cần tự tin và chủ động hơn trong việc trình bày ý kiến, thảo luận chuyên môn cũng như xử lý các tình huống giao tiếp trong công việc hàng ngày. "
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": "Đánh giá chung 1. Môi trường làm việc\nMôi trường của First Cloud Journey rất chuyên nghiệp và truyền cảm hứng. Các buổi workshop được tổ chức bài bản với nội dung cập nhật và thiết thực. Diễn giả và mentor đều là các chuyên gia có kinh nghiệm, nhiệt tình giải đáp thắc mắc\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ tận tay.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi sự kiện nội bộ là một điểm cộng lớn.\n"
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/aws-workshop/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]